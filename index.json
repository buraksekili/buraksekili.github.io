[{"content":"This blog post is a collection of my personal notes on networking. For a long time, I had to jump between different notebooks to connect concepts; from core networking theory, to Linux internals, all the way up to Kubernetes and CNI. This post is my attempt to combine all those notes into a single, logical document.\nWe\u0026rsquo;ll follow a step-by-step path. We\u0026rsquo;ll start with fundamental network concepts, then see how those are implemented in Linux, which is the foundation for most modern virtual networking. Finally, we\u0026rsquo;ll see how Kubernetes builds on top of it all.\nAs a quick disclaimer, I\u0026rsquo;m writing this from the perspective of a software engineer, not a network engineer. This post is the guide I wish I\u0026rsquo;d had, and I\u0026rsquo;m sharing my learning journey in the hope that it\u0026rsquo;s as helpful to you as it has been to me.\nNetworking Feel free to skip this section if you are familiar with Switch vs Router comparison at least.\nLet\u0026rsquo;s start with fundamentals. Networking in general usually involves a lot of terminologies and acronyms, which makes it a bit challenging, at least for me, to understand when I need to check something. Therefore, understanding certain fundamental concepts might be helpful even in general tech literacy, even if you are not a networking engineer.\nA \u0026ldquo;host\u0026rdquo; is almost any device connected to a network, like your phone, computer, server, or printer. So, \u0026lsquo;host\u0026rsquo; is a widely used term, and it does not only mean \u0026lsquo;server\u0026rsquo;; it can be any device connected to a network. But what is a network? It is the underlying communication fabric, built from physical links, hardware, firmware, and software. It uses protocols to provide communication, or in other words, packet-delivery services, between these hosts. As an example, if you have multiple devices connected together with patch cables (like a router and your laptop), it creates a local area network, a LAN - in most simple setups, unless advanced isolation techniques are used.\nNow you have a local network where multiple devices (laptops, phones, etc.) are connected to each other. The next question is, how do those hosts communicate? We need a way to say, \u0026ldquo;Okay \u0026rsquo;laptop-xyz\u0026rsquo;, send this request to my printer \u0026lsquo;printer-abc\u0026rsquo;.\u0026rdquo; That\u0026rsquo;s where the MAC address comes into play. A MAC address is a unique hardware ID assigned to a machine, usually by its producer. For one host to send data to another on the same LAN, it must send that data to the receiver\u0026rsquo;s MAC address.\nThat\u0026rsquo;s good, but what happens if we change our laptop? The new laptop will have a new MAC address. If we only used MAC addresses, we would have to reconfigure everything to find the new one. As you can see, this would be a hassle and is an infeasible way to maintain a network, especially since devices are always joining and leaving.\nThis brings up a new problem. The MAC address solves the \u0026lsquo;where\u0026rsquo; problem: where to send the packet on the local network. But it\u0026rsquo;s not good for the \u0026lsquo;who\u0026rsquo; problem: who is the device I want to talk to, regardless of its specific hardware? This is why we have IP addresses (this is not the only reason of course). An IP address is a logical address assigned to a host. It\u0026rsquo;s the stable \u0026ldquo;who\u0026rdquo; we want to communicate with.\nAlso, please note that we don\u0026rsquo;t use IP addresses instead of MAC addresses; we use them together. Your application sends a packet to an IP address (the logical \u0026lsquo;who\u0026rsquo;). Then, your computer uses a special protocol to find the current MAC address (the physical \u0026lsquo;where\u0026rsquo;) associated with that IP. This two-part system gives flexible logical addressing (IPs) while still using the hardware MAC addresses to deliver the data on the local network to correct device.\nBut then, you may be wondering: how does a host find the MAC address for an IP address on its local network? This is done using the Address Resolution Protocol (ARP). For example, if host-a wants to send a packet to host-b (IP: 10.0.0.59), host-a initially has no idea what host-b\u0026rsquo;s MAC address is. It first broadcasts an ARP request to the entire network, basically asking, \u0026ldquo;Who has the IP address 10.0.0.59? Send me your MAC\u0026rdquo;. Every host on the network receives this broadcast, but only host-b recognizes its own IP and then sends an ARP reply directly back to host-a, saying, \u0026ldquo;I have 10.0.0.59, and here is my MAC address.\u0026rdquo; Once host-a learns host-b\u0026rsquo;s MAC address, it can send its packet destined to host-b\u0026rsquo;s MAC address.\nSwitch Assume that our LAN has evolved and grown. Connecting every device directly to every other one becomes unscalable. The solution is a switch. Each device is connected to switch through ports located on the switch. Switch knows where to find those hosts based on the host\u0026rsquo;s connected port on switch. For example, if host-a and host-b are connected to port-1 and port-2 ports respectively, if host-a wants to send a packet to host-b, the switch knows that host-b is behind its port-2.\nThe most important feature of switch is that it allows communication within a network, using MAC addresses. This is quite important as we\u0026rsquo;ll need to refer to this switch feature in a lot of different places.\nRouter The switch handles traffic within our network, but what happens when a device wants to communicate with a device on a different network, like a server on the internet? The switch, looking at the destination MAC address, will see that it\u0026rsquo;s not a local device and will send the data to the network\u0026rsquo;s exit point, the router.\nRouters allow communication between networks. This is one of the crucial differences between switch and router. Traffic within a local network is usually handled by switch. But once the packet needs to reach wide area network (WAN), or in other words another network on the Internet, we need a router.\nRouter knows which networks that they can route by maintaining a routing table, allowing them to know where the corresponding IP address may be found in the WAN. When your router receives a data packet destined for Google, it doesn\u0026rsquo;t know Google\u0026rsquo;s MAC address but IP address. It consults its routing table and forwards the packet to the next router on the path, which repeats the process. This forwarding across many different networks is what allows you to reach any destination on the internet.\nSo, the key takeaways are that switching uses MAC addresses to move data within a single network, while routing uses IP addresses to move data between different networks.\nOSI (L2, L3 and L4) We are not going to dive into details of OSI layers; but it\u0026rsquo;s usually good to be familiar with certain mechanisms and terminologies related to OSI layers in general, as it helps us to understand more complex systems like container networking and Kubernetes.\nLayer 2 Layer 2, the Data Link Layer, interacts between the Layer 3 (Network) and Layer 1 (Physical) layers. Its main responsibility is to take Layer 3 packets (like IP packets) and encapsulate them into frames for transmission over a physical medium. Also, it receives incoming signals from L1, reassembles them into frames, de-encapsulates them and passes the payload (the original L3 packet) up the stack.\nL2 uses a special addressing scheme called MAC to manage the delivery. By using MAC, L2 identifies the receiver host, and sends the data to the correct host.\nYour data travels across different hosts, for instance host to switch (which is a host) then another host to router, etc etc until it reaches its destination. This process is usually done by devices like network cards (NICs), or switch. As we saw previously, switch allows communication within a network. If devices are connected by a switch, the switch forwards packets between devices, to ensure host to host communication in a network.\nThe key takeaway for L2 is that it provides a mechanism for host-to-host (or host-to-router) delivery, which is the ability to move a frame from one host to another within the same broadcast domain (e.g., host-to-host on the same LAN, or host-to-router). And switch is mainly a L2 device; though you can find L3 switches on the market as well :).\nLayer 3 Sending data between connected hosts is not our usual Internet experience. We need to send our packets to other networks to access services on those networks. L2 delivery only ensures host-to-host delivery which happens in a single network. However, usual packets need to go beyond that, across networks involving multiple host-to-host deliveries. This is where L3 comes into picture.\nL3 ensures routing of packets and end to end delivery. It uses its own addressing scheme called IP addresses which, unlike physical MAC addresses, are not tied to specific hardware. A router, the key L3 device, makes this work. When a router receives a packet, it reads the destination IP address. It then consults its routing table (a set of rules) to decide where to forward that packet next.\nThe key takeaway is that L3 provides the end-to-end logic for packet delivery across multiple networks. It does this by making a series of hop-by-hop routing decisions using IP addresses.\nIn the following example, we have two networks connected to each other via Router:\nNetwork 1 (10.0.0.0/24) Network 2 (71.0.0.0/24) ┌──────────────────────┐ ┌───────────────────────┐ │ │ IF2: │ │ │ │ MAC: DD │ │ │ │ IP: 71.0.0.1 │ │ │ HOST A │ Router │ HOST B │ │ ┌─────────────┐ │ xxxxxxxxx │ ┌─────────────┐ │ │ │MAC: AA │ │ x x │ │MAC: BB │ │ │ │ ┼───│──\u0026gt; x x────────\u0026gt; │ │ │ │ │ │IP: 10.0.0.50│ │ x x │ │IP: 50.0.2.19│ │ │ └─────────────┘ │ xxxxxxxxx │ └─────────────┘ │ │ │ IF1: │ │ │ │ MAC: CC │ │ │ │ IP: 10.0.0.1 │ │ └──────────────────────┘ └───────────────────────┘ Host A (10.0.0.50) wants to send a packet to Host B (71.0.0.59). Host A checks its own local routing table. It compares the destination 71.0.0.59 to its own network (subnet, 10.0.0.0/24) and determines the destination is not its own network. So, it sends the packet to router which is usually defined as default gateway. In order to create the L2 frame, Host A needs the MAC address associated with 10.0.0.1. It uses ARP (Address Resolution Protocol), broadcasting a request: \u0026ldquo;Who has 10.0.0.1? The router\u0026rsquo;s IF1 interface replies: \u0026ldquo;I have 10.0.0.1, and my MAC is CC.\u0026rdquo; Host A now builds the packet and encapsulates it in an L2 frame to send to the router:\n# Frame 1: Host A -\u0026gt; Router (on Network 1) destination MAC: CC source MAC: AA --- (L3 Header) --- destination IP: 71.0.0.59 source IP: 10.0.0.50 --- (Payload) --- The router receives this frame on IF1 as the destination MAC matches, strips the L2 header and inspects the L3 header. Since the destination IP is 71.0.0.59, the router sends this packet to IF2 by creating again L2 header with the similar process (ARP request and then updating L2 header accordingly).\nThe router re-encapsulates the original, unchanged L3 packet into a new L2 frame, using its IF2 MAC (DD) as the source.\n# Frame 2: Router -\u0026gt; Host B (on Network 2) destination MAC: BB source MAC: DD --- (L3 Header) --- destination IP: 71.0.0.59 source IP: 10.0.0.50 --- (Payload) --- Finally, Host B receives this frame, strips the L2 header, and inspects the L3 header. It sees its own IP as the destination and accepts the packet, passing the payload up the stack.\nAgain, the key takeaway from this example is that the L3 header (IPs) remained constant for the entire end-to-end delivery, while the L2 header (MACs) was rebuilt at each hop.\nLayer 4 We have delivered the packet to the correct host (HB), but when a packet reaches to its destination, that host might be running manny different programs, like a web server, an email server, etc. So, how do we know which program the packet is for? This is the job of Layer 4 (L4), the Transport Layer. This L4 header specifies a port number. For example, if HA wants to reach HB\u0026rsquo;s web server, it will set the destination port in the L4 header to 80. When HB receives the L3 packet and unwraps it, it looks at this L4 header, sees \u0026ldquo;port 80,\u0026rdquo; and knows to deliver the data to its web server, not its email server. This is how a single IP address can serve many different services at the same time.\nSwitching (L2 Domain) We\u0026rsquo;ve covered the basics of a switch, but how does it actually manage traffic magically? This section explains the fundamental operations a switch performs.\nAs mentioned earlier, switches have multiple ports where devices (like PCs and servers) connect. To know where to send traffic, a switch builds and maintains a MAC address table. This table is crucial: it maps the MAC address of a connected device to the specific switch port it\u0026rsquo;s on. This table is what allows the switch to intelligently deliver frames to the correct destination.\nWhen a frame arrives on any port, the switch follows a simple but powerful three-step logic: Learn, Flood, and Forward.\nA Quick Note that the \u0026ldquo;Learn, Flood, and Forward\u0026rdquo; model is the most fundamental concept of L2 switching. Please be aware that this overview explains only the basics. Real-world switches perform several other important functions, such as filtering frames (dropping a frame if the destination is on the same port it came from) and aging out (removing) old entries from the MAC table to keep it up-to-date.\nLearn Switch maintains its MAC table with the port and updates it whenever a related frame passes through the switch. For example, when Host A sends a frame to Host B, the initial MAC table state is empty. When the switch receives a traffic from Host A\u0026rsquo;s MAC address (let\u0026rsquo;s say AA) through port-a, switch learns and updates its MAC table to memorize port: port-a and MAC: AA.\nFlood Now, switch still does not know where to find Host B (which port should it use?). Therefore, the switch floods a unicast frame out all switch ports except the port it was received on. This is called flooding. Once Host B receives the frame, it responds to the message through a port that it\u0026rsquo;s connected to, let\u0026rsquo;s say port-b. Now, switch receives this acknowledged response through port-b, and learns that port: port-b and MAC: BB. Now, switch knows where to find Host B\nFORWARD The rest is a bit trivial actually. The switch knows ports and MAC addresses. It performs forwarding to deliver the frame. The Forward operation is the main job of the switch once its MAC table has information.\nAfter the switch \u0026ldquo;learns\u0026rdquo; that Host B is on port-b, the \u0026ldquo;Flood\u0026rdquo; process is no longer needed to reach it. The next time Host A sends a frame to Host B, the switch receives it, looks at the Destination MAC address (BB), and checks its MAC table. It finds the entry for it port: port-b and MAC: BB and forwards the frame only out port-b. It drastically reduces network traffic and is the primary reason switches are much more efficient than old hubs.\nRouting (L3 Domain) Routing is the process of delivering data between different networks (inter-network communication) using a device called a router. This operation occurs at Layer 3 (L3) of the OSI model. If a host on one network (like your home LAN) needs to communicate with a host on a different network (like the internet), it requires a router to forward the packet.\nRouting Table Routers maintain a map of all the networks they know about, which is known as routing table. This table is essentially a set of rules, or routes, that tell the router which path to use to reach a specific network destination.\nExample routing table contents, from https://en.wikipedia.org/wiki/Routing_table\nNetwork destination Netmask Gateway Interface Metric 0.0.0.0 0.0.0.0 192.168.0.1 192.168.0.100 10 127.0.0.0 255.0.0.0 127.0.0.1 127.0.0.1 1 192.168.0.0 255.255.255.0 192.168.0.100 192.168.0.100 10 192.168.0.100 255.255.255.255 127.0.0.1 127.0.0.1 10 192.168.0.1 255.255.255.255 192.168.0.100 192.168.0.100 10 You might wonder how this table is created. Routes are typically added in three ways:\nDirect: the router automatically adds routes for networks it is physically connected to (e.g., the 192.168.0.0 entry). Static: a fixed route is manually added. Dynamic: routers peers each other (talks to each other) using routing protocols (like OSPF or BGP) to automatically learn about and share routes. This is essential in large, complex networks. If you have checked Kubernetes networking related documents, you may realize that routing protocols, especially BGP, are usually mentioned as an option in the network fabric. BGP (Border Gateway Protocol) allows different networks to exchange routing information automatically. While it\u0026rsquo;s an advanced topic, the key idea is automated route discovery, and we will see BGP again when we discuss advanced networking patterns in Kubernetes. Also, if you are using managed services from cloud providers, as an end user, most of the time you do not need to work closely with BGP. This is because most cloud providers use an abstraction called \u0026ldquo;overlay networks\u0026rdquo; which we will also briefly see in the Kubernetes networking section. These overlays run on top of the provider\u0026rsquo;s complex underlying network, which itself may use BGP heavily, but that complexity is hidden from you.\nA key entry in many routing tables is the default gateway (shown as 0.0.0.0 in the example). This is the \u0026ldquo;catch-all\u0026rdquo; route. If the router doesn\u0026rsquo;t have a specific route for a destination, it sends the packet to the default gateway if its defined. So, the default gateway is optional. So, based on the routing table, the kernel forwards data to the route.\nNAT NAT is a process where a router modifies the source and/or destination IP addresses in a packet\u0026rsquo;s header on the fly as it passes through.\nPublicly routable IP addresses (like the ones you get from your ISP) are a limited (due to the nature of unique IPv4 addresses) and costly resource. In a typical home or office, your devices (laptops, phones) use private IP addresses (e.g., 192.168.x.x, 10.x.x.x). These addresses are not routable on the public internet. Only your main router has a single public IP address.\nThen you may ask, how can your private device access the internet? And just as importantly, if a web server sends a response, how does it get back to your specific private device, which it can\u0026rsquo;t see?\nThis is solved by two main types of NAT:\nSNAT (source NAT) SNAT is the process where source IP is changed. This is important because addresses in LAN are not reachable from WAN. Thus, even though they can send requests to internet, internet can\u0026rsquo;t respond to those hosts. So, SNAT is being used for outbound connections, like when your laptop browses a website.\nThe process begins when your laptop (private host, e.g., 192.168.0.100) sends a packet to a web server (e.g., 8.8.8.8). This packet, with its private source IP, hits your router. The router then performs SNAT by changing the packet\u0026rsquo;s Source IP from 192.168.0.100 to its own public IP (e.g., 123.45.67.89). Also, it records this translation in a state table. The web server receives the packet from the public IP and sends its response back to that same public address. When your router receives this response, it checks its state table, sees the traffic belongs to 192.168.0.100, and translates the Destination IP back to your private host before forwarding it.\nDNAT (destination NAT) This is used for inbound connections, often called port forwarding. Imagine you are hosting a web server on your private network at 192.168.0.200. Since someone on the internet can\u0026rsquo;t reach this private address, you configure a DNAT rule on your router. This rule tells the router, \u0026ldquo;Any traffic that arrives at my public IP (123.45.67.89) on a specific port (like port 80 for HTTP) should have its Destination IP changed to 192.168.0.200.\u0026rdquo; This rule forwards the external request to your internal, private server, allowing it to host services for the public internet.\nThis entire stateful process requires the router to remember which internal host initiated which external connection. This mechanism is called connection tracking (or conntrack in Linux).\nThe conntrack system maintains an in-memory table of all active connections. For SNAT, this table maps the original [private_ip:port] to the [public_ip:port] it was translated to. Because this table is stored in memory, it has a limited size. This limit (e.g., nf_conntrack_max in Linux) can be reached if you have too many simultaneous active connections. It can also be a problem with a high rate of short-lived connections, as entries are kept in the table for a short time even after the connection closes. If this table fills up, the router will start dropping new connections.\nLinux Networking (Single Host) This section covers the common Linux networking \u0026ldquo;toolbox\u0026rdquo; required to understand before jumping into Kubernetes networking. We\u0026rsquo;ll use standard Linux tools to build a complete, virtualized network inside a single host. The concepts we explore network namespaces, veth and virtual bridges that are the building blocks used by container runtimes and CNI. A grasp of these operations and concepts is key to understanding how container networking operates at scale.\nIf you are already comfortable with container networking, feel free to skip ahead.\nIsolation (network namespaces) As explained in Layer 2 section, a host uses network interfaces (NICs) for network communication. These interfaces can be physical (like the actual hardware on your laptop) or virtual, which we will discuss soon.\nWhen you start your Linux machine, the kernel runs a single, default networking stack for you to manage all networking processes. This \u0026ldquo;root\u0026rdquo; stack is for everything running on the Linux machine. If you need to isolate this stack, you should use network namespaces.\nLike other Linux namespaces, network namespaces isolate the networking stack. This allows us to spin up multiple containers on the same host while managing their networking stack differently, giving each one its own isolated network devices, firewall rules, ports, and route tables.\nThis isolation is very strong. When a network namespace is created, it comes with only a single, private loopback device (lo). It has no other interfaces, no routes, and no way to communicate with the host or the outside world. The rest of the configuration must be set by hand. To make this isolated \u0026ldquo;box\u0026rdquo; useful, we must provide it with a network connection. The most common method, and the one that powers container networking, is to use a virtual ethernet (veth) pair, which acts like a virtual patch cable.\nThe main tool we will use throughout this section is the ip command. The following is a quick demonstration of ip tool in Linux to manage network namespaces\nFor a more detailed reference, the ip command suite is vast. RedHat provides a useful cheatsheet: https://access.redhat.com/sites/default/files/attachments/rh_ip_command_cheatsheet_1214_jcs_print.pdf.\n1 2 3 4 # adding a network namespace ip netns add \u0026lt;namespace_name\u0026gt; # executing a command in this namespace. ip netns exec \u0026lt;namespace_name\u0026gt; $COMMAND Let\u0026rsquo;s run a quick demo to see this isolation in action. We\u0026rsquo;ll create a namespace called \u0026ldquo;container0\u0026rdquo; and run a shell inside it:\n1 2 3 4 5 6 7 8 9 10 11 ip netns add container0 ip netns list # container0 (id: 0) ip netns exec container0 /bin/bash ip netns identify # this should print container0 exit # exit from container0 namespace ip netns identify # this should print nothing as we are in the root namespace ip netns del container0 Network Device abstraction (ip link) If you have come across ip commands before (or check the cheat sheet above), you may realize that ip link is widely used. This utility provides a great configuration layer for our isolated environment, by providing network device configuration.\nIn the last section, we used the ip netns command to manage the namespace itself. Now, we\u0026rsquo;ll use ip link to manage the network devices (or interfaces) inside the namespace.\nYou\u0026rsquo;ll often hear these called network interfaces, link devices, or just links. These terms all refer to the same basic concept of a kernel object that can send or receive packets. They can have technical differences, but usually they refer to the similar functionality; sending and receiving data.\n1 2 3 $ ip netns add container0 \u0026amp;\u0026amp; ip netns add container1 \u0026amp;\u0026amp; ip netns container0 container1 Now, let\u0026rsquo;s use ip link show to see what network devices exist inside container0:\n1 2 3 $ ip netns exec container0 ip link show 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 As you can see, the namespace isn\u0026rsquo;t empty; it starts with a single device: lo, the loopback interface. This virtual device allows a host (or in this case, a namespace) to send network packets to itself.\nIf you examine this output, you\u0026rsquo;ll see the loopback device\u0026rsquo;s current state is DOWN. This means the device is not \u0026ldquo;up\u0026rdquo; or ready to function. But, what is the meaning of all of this? Why would you even care? Let\u0026rsquo;s try something simple, like pinging the loopback IP address 127.0.0.1:\n1 2 $ ip netns exec container0 ping 127.0.0.1 ping: connect: Network is unreachable It fails. We get \u0026ldquo;Network is unreachable\u0026rdquo; because even though the lo device exists, it\u0026rsquo;s turned off, and the kernel can\u0026rsquo;t use it. Let\u0026rsquo;s fix this by using the ip link set command to bring the device \u0026ldquo;up\u0026rdquo;:\n1 2 3 4 5 6 7 8 $ ip netns exec container0 ip link set lo up $ ip netns exec container0 ping -c 1 127.0.0.1 PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.082 ms --- 127.0.0.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.082/0.082/0.082/0.000 ms It works. We have just configured our first network device. This lo interface is essential, but it only lets the namespace talk to itself. To talk to other namespaces or the outside world, we need to add new devices.\nThe cable (veth pairs) Virtual Ethernet, or veth, does what we are looking for: it connects our namespace to another namespace.\nIn our above example, let\u0026rsquo;s assume we want to allow communication between container0 and container1. What can we do? Remember the concepts mentioned in Networking section. The simplest way to connect hosts was connecting them together with patch cable. However, we now operate in the virtualized world. How could we make it? In the virtualized world, veth achieves this for us.\nA virtual ethernet device, or veth for short, is a link device that is created as a pair, just like a patch cable. When a packet is transmitted on one end of veth, it is received from the other end. Thanks to this feature, we use a veth pair to connect container0 and container1 directly.\n+------------------------------------------------+ | | | container0 container1 | | +--------------+ +--------------+ | | | | | | | | | | | | | | | | | | | | +------+-------+ +------+-------+ | | ^ ^ | | | | | | | veth | | | +-----------------------+ | | | +------------------------------------------------+ The above diagram is what we want to achieve, so that we can ping container0 to container1.\n1 ip link add veth0 type veth peer name veth1 The command may look ugly, but if we read it as:\n\u0026lt;ip link add veth0\u0026gt; \u0026lt;type veth\u0026gt; \u0026lt;peer name veth1\u0026gt; It makes it a bit clearer to understand. It means we want to add a link device called veth0, whose type is veth. Since it\u0026rsquo;s going to be a veth, we need to give a name to its peer, or in other words, its other end.\nWhere should we run this command? Within the container0 or container1 namespaces, or on the host? Well, we usually create the veth pair in the parent namespace (the host, in our case) and then move each end into its corresponding namespace.\nNow, let\u0026rsquo;s list what link devices we have in the host network namespace:\n1 2 3 4 5 6 7 8 9 $ ip netns identify $ ip link show 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 49: veth1@veth0: \u0026lt;BROADCAST,MULTICAST,M-DOWN\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether ea:de:62:55:a0:7a brd ff:ff:ff:ff:ff:ff 50: veth0@veth1: \u0026lt;BROADCAST,MULTICAST,M-DOWN\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 56:10:cf:46:97:1c brd ff:ff:ff:ff:ff:ff As you can see, the veth pair is there, and both devices are state DOWN Now, we\u0026rsquo;ll move one end into container0 and the other into container1:\n1 2 3 4 5 6 7 8 9 10 $ ip link set veth0 netns container0 \u0026amp;\u0026amp; ip link set veth1 netns container1 $ ip netns exec container0 ip addr show 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 50: veth0@if49: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 56:10:cf:46:97:1c brd ff:ff:ff:ff:ff:ff link-netns container1 The IPs for network devices are visible in ip addr show output. If you check inet field, its the IPv4 address, and inet6 corresponds to IPv6 address.\nOkay, now both containers are connected. Perfect, can we now ping the container1 from container0? Well, which address should we use? There is no IP address for the containers at the moment. What should get an IP address; namespace, the veth or something else? How can we assign an IP address?\nWell, based on our discussion in the Networking section, we assumed hosts (devices) have IP addresses. So, we assign IP to network interfaces to allow communication through IP. In our case, the \u0026ldquo;device\u0026rdquo; is the veth pair. Since veth is a link device (a network interface), we can assign an IP to it and ping that IP. Assigning IPs can be done via the ip command.\n1 2 3 $ ip netns exec container0 ip addr add 10.0.1.50/24 dev veth0 $ ip netns exec container1 ip addr add 10.0.1.59/24 dev veth1 $ ip netns exec container0 ip link set dev veth0 up \u0026amp;\u0026amp; ip netns exec container1 ip link set dev veth1 up This command assigns 10.0.1.50/24 to veth0 and 10.0.1.59/24 to veth1. Since both of these IPs are in the same 10.0.1.0/24 subnet, the kernel will know they can reach each other directly over the veth \u0026ldquo;cable\u0026rdquo; through L2 network, without routing.\nBy calling ip link set dev veth0 up, we are setting the link (device, network interface) up, or ready to function.\nLet\u0026rsquo;s check the IP addresses:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ ip netns exec container0 ip addr show veth0 50: veth0@if49: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 56:10:cf:46:97:1c brd ff:ff:ff:ff:ff:ff link-netns container1 inet 10.0.1.50/24 scope global veth0 valid_lft forever preferred_lft forever inet6 fe80::5410:cfff:fe46:971c/64 scope link valid_lft forever preferred_lft forever $ ip netns exec container1 ip addr show veth1 49: veth1@if50: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether ea:de:62:55:a0:7a brd ff:ff:ff:ff:ff:ff link-netns container0 inet 10.0.1.59/24 scope global veth1 valid_lft forever preferred_lft forever inet6 fe80::e8de:62ff:fe55:a07a/64 scope link valid_lft forever preferred_lft forever Based on inet output, we can see that veth devices have IP addresses as we defined above.\nNow, we should test if container0 can reach container1 by simply pinging IP addresses within the container network namespaces:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ ip netns exec container0 ping -c 1 10.0.1.59 # pinging container1 within container0 PING 10.0.1.59 (10.0.1.59) 56(84) bytes of data. 64 bytes from 10.0.1.59: icmp_seq=1 ttl=64 time=0.031 ms --- 10.0.1.59 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.031/0.031/0.031/0.000 ms $ ip netns exec container1 ping -c 1 10.0.1.50 # pinging container0 within container1 PING 10.0.1.50 (10.0.1.50) 56(84) bytes of data. 64 bytes from 10.0.1.50: icmp_seq=1 ttl=64 time=0.300 ms --- 10.0.1.50 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.300/0.300/0.300/0.000 ms It works. We have successfully created our first virtual network by connecting two isolated namespaces with a veth pair.\nThe Virtual Switch (bridge) Having two containers and managing a direct connection between them is not a big deal. We just need to perform a couple of commands, and the two isolated network namespaces are ready to communicate.\nHowever, think about scaling this system. If you have many containers, connecting them to each other directly will not scale. Does this issue sound familiar? Remember one of the benefits of switches. In the physical world, switches solve this exact problem. Instead of connecting hosts directly to each other, we connect all hosts to a central switch, which then handles communication between them.\nA similar solution exists in the virtualized environment, and in Linux, it\u0026rsquo;s called a bridge.\nA Linux bridge is a Layer 2 device that behaves exactly like a virtual switch. It builds a MAC address table and forwards frames between the devices connected to it. Because it\u0026rsquo;s L2, it does not know about IP addresses or routes.\nFrom the host\u0026rsquo;s point of view, the bridge is just another network device (a link). From the containers\u0026rsquo; point of view, it\u0026rsquo;s the \u0026ldquo;switch\u0026rdquo; they are all plugged into.\nOur old setup was a direct veth \u0026ldquo;patch cable\u0026rdquo; between two containers: Our new setup will look like this, with a central br0 bridge: In this setup, introducing a new container or removing a new container (network namespaces) become quite easy. We just need to perform operations that we explained above. But instead of connecting veth pairs to host network, we connect one end of veth pair to bridge, and the another to container itself.\nTo set this up, we\u0026rsquo;ll create a br0 bridge device in the host namespace. Then, for each container, we\u0026rsquo;ll create a veth pair. One end will go inside the container namespace (and get the IP address), while the other end will be \u0026ldquo;plugged into\u0026rdquo; the bridge as a port.\nLet\u0026rsquo;s build this. First, we need to create the bridge device. We\u0026rsquo;ll use the ip command again.\n1 2 3 # create a device of type \u0026#39;bridge\u0026#39;, named \u0026#39;br0\u0026#39; ip link add br0 type bridge ip link set br0 up That\u0026rsquo;s it. We now have a virtual switch that is on, but has nothing plugged into it. Now, let\u0026rsquo;s clean up our old setup and connect our containers to this new bridge.\nMaybe you may want to try it yourself, by following the commands in the previous section.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # clean up the old veth pair # note that deleting one end also deletes the peer ip netns exec container0 ip link del veth0 # create new veth pairs for container0 and container1 # (c0-veth, c0-br) -\u0026gt; for container0 # (c1-veth, c1-br) -\u0026gt; for container1 ip link add c0-veth type veth peer name c0-br ip link add c1-veth type veth peer name c1-br # move the \u0026#39;veth\u0026#39; end into the namespaces ip link set c0-veth netns container0 ip link set c1-veth netns container1 # attach the \u0026#39;br\u0026#39; veth end to the bridge # this is like plugging the cable into the switch ip link set c0-br master br0 ip link set c1-br master br0 # add IP addresses to veth pairs inside the containers ip netns exec container0 ip addr add 10.0.1.50/24 dev c0-veth ip netns exec container1 ip addr add 10.0.1.59/24 dev c1-veth ip netns exec container0 ip link set dev c0-veth up ip netns exec container1 ip link set dev c1-veth up # also do not forget to set \u0026#39;br\u0026#39; veth pair ends UP ip link set c0-br up ip link set c1-br up Now the setup is complete. We expect the similar behaviour, where containers can ping each other.\n1 2 3 4 5 6 7 $ ip netns exec container1 ping -c 1 10.0.1.50 PING 10.0.1.50 (10.0.1.50) 56(84) bytes of data. 64 bytes from 10.0.1.50: icmp_seq=1 ttl=64 time=0.092 ms --- 10.0.1.50 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.092/0.092/0.092/0.000 ms It works! You may wonder the purpose of all hassle by setting up the bridge. Since bridges work like virtual switches, adding a new container to this setup becomes easier than before. We just need to add veth pairs, connect one end of the pair to container and another end to the bridge, assign IP address and set everything UP. Now the new container also can communicate with other containers, so we do not need to update every veth pair in other containers.\nWe have now built a scalable, single-host virtual network, which is the foundation of how Kubernetes and CNI work.\nL3 Gateway Our containers can communicate with each other. That\u0026rsquo;s perfect for offline environments. But most of the time, we also expect containers to reach other networks, especially the Internet.\nLet\u0026rsquo;s check whether the containers can communicate with the Internet.\n1 2 3 4 $ ip netns exec container0 ping -c 1 8.8.8.8 ping: connect: Network is unreachable $ ip netns exec container1 ping -c 1 8.8.8.8 ping: connect: Network is unreachable Even though containers can ping each other, they cannot communicate with the Internet.\nRemember, in the previous sections, we explained how packet delivery happens: L2 ensures host-to-host (or host-to-router) delivery, while L3 ensures end-to-end delivery. What are we missing here?\nThe simple answer is that the container network namespaces do not know any path to reach 8.8.8.8. Therefore, they cannot deliver the ping request (ICMP packets). We need to add a \u0026lsquo;route\u0026rsquo; to instruct our system to find the path. In our host machine, we are able to ping the Internet. It seems the host namespace contains a route allowing it to access the internet, and this route does not exist in the containers.\nIn our host machine, we are able to ping the Internet. It seems the host namespace contains a route allowing it to access the internet, and this route does not exist in the containers.\nTo find out the reasons, we should look at how we reach the Internet from the host:\n1 2 3 4 $ ip netns identify \u0026amp;\u0026amp; ip route get 8.8.8.8 8.8.8.8 via 192.168.215.1 dev eth0 src 192.168.215.2 uid 0 cache ip route get \u0026lt;address\u0026gt; command allows us to check which route the host takes while reaching \u0026lt;address\u0026gt;. In our case, we reach 8.8.8.8 via the eth0 device. If you list all routes, you\u0026rsquo;ll see why:\n1 2 3 $ ip route default via 192.168.215.1 dev eth0 192.168.215.0/24 dev eth0 proto kernel scope link src 192.168.215.2 As we mentioned in Routing Table section, the first entry is the default gateway, which is used if no other rule is matched. By using this rule, we are able to ping the Internet. We need to add a similar route inside the container namespaces.\nLet\u0026rsquo;s first check the full routing table inside container0:\n1 2 3 4 $ ip route 10.0.1.0/24 dev c0-veth proto kernel scope link src 10.0.1.50 $ ip route get 8.8.8.8 RTNETLINK answers: Network is unreachable This confirms our suspicion. The only rule it knows is the \u0026ldquo;direct\u0026rdquo; route for its local subnet. When we ask it to find 8.8.8.8, it doesn\u0026rsquo;t match this rule, and there\u0026rsquo;s no \u0026ldquo;default\u0026rdquo; to fall back on.\nSo, how do we give the containers a default route? We need to give them a gateway (a router) that they can send all non-local traffic to. The perfect candidate for this gateway is our own br0 bridge.\nYou might ask, why the bridge? In our last example, br0 was just a simple L2 switch and didn\u0026rsquo;t have an IP at all. This is the key difference: to act as an L3 gateway, a device should have an IP address. A fundamental rule of IP networking is that a host\u0026rsquo;s gateway must be on the same local subnet. This is so the container (e.g., 10.0.1.50) can use ARP to find the gateway\u0026rsquo;s MAC address. Therefore, we will turn our L2 switch into an L3 gateway by assigning it an IP address on the containers\u0026rsquo; subnet, 10.0.1.0/24.\nIf the bridge were only acting as a simple L2 switch for a network that didn\u0026rsquo;t need to talk to the outside world, it wouldn\u0026rsquo;t need an IP.\nWe\u0026rsquo;ll use 10.0.1.1 as the gateway IP. This will be the \u0026ldquo;internal\u0026rdquo; IP of our router, reachable by both containers.\nIt is not mandatory but convention to give a.b.c.1 IP addresses to the Gateway.\n1 2 3 $ ip addr add 10.0.1.1/24 dev br0 $ ip addr show br0 | grep -e \u0026#34;inet \u0026#34; inet 10.0.1.1/24 scope global br0 Now, lets also instruct container network stack to route any non-local packets to bridge IP.\n1 2 3 4 5 6 7 $ ip netns exec container0 ip route add default via 10.0.1.1 $ ip netns exec container1 ip route add default via 10.0.1.1 # let\u0026#39;s check the route table for container0 again $ ip netns exec container0 ip route default via 10.0.1.1 dev c0-veth 10.0.1.0/24 dev c0-veth proto kernel scope link src 10.0.1.50 Now container know that any traffic not destined for 10.0.1.0/24 should be sent to the gateway at 10.0.1.1. Let\u0026rsquo;s test the connection:\n1 2 3 4 5 $ ip netns exec container0 ping -c 1 8.8.8.8 PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data. --- 8.8.8.8 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms It still fails! Why?\nThis may be confusing, since our containers can talk to each other. That\u0026rsquo;s because the traffic between namespaces is a Layer 2 (switching) operation. The br0 bridge acts like a physical switch, and the packets never leave the bridge to be routed. The host\u0026rsquo;s main L3 (IP) routing engine isn\u0026rsquo;t involved. If you remember the switching operations (learn, flood, forward) in Switching section, you may remember that Switch actually knows which MAC addresses are connected to which ports. This operation only applies to within network traffic as we explained in the first section.\nHowever, ping 8.8.8.8 is a Layer 3 (routing) operation. The container sends the packet to its gateway (the br0 interface), meaning that we need to reach another network. As you remember, this requires routing as we need to move data between networks. The host\u0026rsquo;s kernel receives this packet on br0 and, after checking its own route table, sees it must send it out a different interface (like eth0).\nThis act of receiving a packet on one interface and forwarding it to another is called L3 forwarding. By default, the Linux kernel disables this for security, so a machine doesn\u0026rsquo;t accidentally act as a router. We must explicitly enable this by setting net.ipv4.ip_forward=1.\nThat\u0026rsquo;s the first problem. The second problem is NAT. The packet from container0 has a source IP of 10.0.1.50. The internet doesn\u0026rsquo;t know how to send a reply to this private IP.\nWe must use iptables to \u0026ldquo;masquerade\u0026rdquo; the packet, rewriting its source IP to the host\u0026rsquo;s public IP (192.168.215.2).\nOkay, you might think, what is iptables since we never mentioned it yet.\nIn simple words, iptables is a program that allows us to set rules for packets. You can create iptables rules to filter, modify, or redirect packets. It\u0026rsquo;s a powerful tool for building firewalls, and it\u0026rsquo;s also commonly used to implement NAT because its rules allow \u0026ldquo;mangling\u0026rdquo; (updating) the packet itself.\niptables is a complex tool, and while it\u0026rsquo;s now being replaced by modern alternatives, its concepts are still fundamental to Kubernetes networking.\nSo, let\u0026rsquo;s update our host machine to enable IP forwarding:\n1 sysctl -w net.ipv4.ip_forward=1 And, we need to add an iptables NAT rule. This command is a bit long, but what it means is that \u0026ldquo;For any packet in the nat table, in the POSTROUTING (after-routing) chain, if it\u0026rsquo;s from our container subnet (-s 10.0.1.0/24) and going out the -o eth0 interface, then -j MASQUERADE (change its source IP to eth0\u0026rsquo;s IP).\u0026rdquo;\n1 iptables -t nat -A POSTROUTING -s 10.0.1.0/24 -o eth0 -j MASQUERADE Now, all the pieces are in place. Let\u0026rsquo;s try one last time:\n1 2 3 4 5 6 7 $ ip netns exec container0 ping -c 1 8.8.8.8 PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data. 64 bytes from 8.8.8.8: icmp_seq=1 ttl=106 time=29.4 ms --- 8.8.8.8 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 29.362/29.362/29.362/0.000 ms Finally it works! We have successfully connected our isolated containers to the internet.\nKubernetes Networking \u0026amp; CNI It\u0026rsquo;s been a long journey but here we are, Kubernetes networking. We are not going to dive into too much details about technical requirements of the Kubernetes networking. Kubernetes\u0026rsquo; official documentation clearly explains the problems that we need to address, as follows:\nHighly-coupled container-to-container communications: this is solved by Pods and localhost communications. Pod-to-Pod communications: this is the primary focus of this document. Pod-to-Service communications: this is covered by Services. External-to-Service communications: this is also covered by Services.\u0026rdquo; https://kubernetes.io/docs/concepts/cluster-administration/networking/\nMotivation and Automation of Linux networking In the last section, we built a single-host virtual network. We manually created namespaces, veth pairs, a bridge, and configured routing. The goal of Kubernetes networking is to automate this entire process at a massive, multi-node scale.\nOne of the core principle of Kubernetes networking is a unique IP per pod model. To understand why this is so important, imagine scaling a web application. You need three replicas, and they all want to listen on port 80. On a single machine, this is impossible, as only one process can bind to a port at a time. This creates a problem of coordinating ports for all your microservices.\nKubernetes solves this by giving every Pod its own isolated network namespace and a unique IP address. Because each Pod has its own network stack (through a dedicated network namespace), there are no port conflicts. Your three replicas can all bind to port 80, each on its own IP (e.g., 10.244.1.10:80, 10.244.2.20:80, 10.244.3.30:80). This simplifies application development and management, as you no longer need to manage port assignments.\nNote: A Pod can also use hostNetwork: true, which skips this process, doesn\u0026rsquo;t get its own IP, and just shares the node\u0026rsquo;s network, but this is for special workloads.\nTo make this model work, Kubernetes requires an L3 network. This means all Pod IPs must be reachable from all other Pod IPs, no matter which node they are on. Therefore, this is quite important and technical aspect that we didn\u0026rsquo;t cover it yet.\nThe first problem Kubernetes networking solves is connectivity: \u0026ldquo;How do we give a Pod its own network namespace and a unique IP, and then make it reachable by other Pods?\u0026rdquo;.\nAnother problem is discovery of Pods. Pods are ephemeral; they can be destroyed and replaced at any time, getting a new IP. This means you can\u0026rsquo;t rely on a Pod\u0026rsquo;s IP address. This is solved by a Kubernetes Service. A Service provides a single, stable virtual IP and a DNS name (e.g., my-service.prod.svc.cluster.local). There is an agent running on each node to manage host level networking and watches the Kubernetes API and updates rules on the host (using iptables, IPVS, or nftables) to map the Service IP to the real Pod IPs. Other tools like Cilium can also do this as kube-proxy replacement, by using eBPF.\nWe also have more problems, for instance reachability, which will be discussed in the next chapter\nCNI (Container Networking Interface) CNI is a specification that tells the container runtime to call a \u0026ldquo;plugin\u0026rdquo; (or program) to handle the network setup for containers.\nIt solves the problem of \u0026ldquo;giving a Pod its own network namespace and a unique IP, and then making it reachable by the cluster\u0026rdquo;. Therefore, we can say that CNI helps to create an isolated network for pod, to allocate the Pod IP, and make the IP reachable by the cluster.\nOur demo in Part 2 where we manually created veth pairs, a bridge, and iptables rules is a good illustration of how one of the most common CNI plugins (the bridge plugin) works under the hood. Other CNI plugins might solve this problem in completely different ways, such as using eBPF, IPVLAN, or different routing techniques.\nWe should indicate that CNI is not only for Kubernetes, it\u0026rsquo;s a generic specification for container networking. Kubernetes in this scenario is just an orchestrator or runtime, which triggers CNI plugins, to set up a network environment for the Pod.\nCNI Plugin According to CNI specification, \u0026ldquo;plugin is a program that applies a specified network configuration\u0026rdquo;. Roughly, the container runtime calls CNI plugin, meaning CNI program, to prepare the container networking. So, if we move the codes that we use in the demo into a bash script and make it executable, it can be good starting point for us to write our own first \u0026ldquo;plugin\u0026rdquo;.\nThough i still do not understand the motivation behind \u0026rsquo;executable\u0026rsquo; plugins, instead of RPC based plugins like other Kubernetes out-tree interfaces (CRI or CSI).\nThe good part about CNI specification is that it allows chaining the plugins. Meaning that you can develop and use existing CNI plugins, and combine them to come up with your own container networking solutions. For example, you can use \u0026ldquo;ipam\u0026rdquo; plugin along with \u0026ldquo;bridge\u0026rdquo; plugin, so that \u0026ldquo;bridge\u0026rdquo; plugin can create the demo environment that we set and \u0026ldquo;ipam\u0026rdquo; plugin can manage the IP address assignment to those resources.\nSince Kubernetes expects more than Pod connectivity, CNI Plugins are usually shipped with additional component(s).\nThe binary is usually the one that we call the plugin. So, its main purpose is configuring the pod network interface, which is for \u0026ldquo;connectivity\u0026rdquo;. Daemon is managing the routing. So, its mainly for \u0026ldquo;reachability\u0026rdquo; There are various ways to ensure \u0026ldquo;connectivity\u0026rdquo; and \u0026ldquo;reachability\u0026rdquo;, and we saw one possible solution for \u0026ldquo;connectivity\u0026rdquo;, in our bridge example.\n\u0026ldquo;Reachability\u0026rdquo; though require more work. The CNI specification itself does not involve reachability; it covers the container networking (connectivity) and some runtime (e.g, Kubernetes) rules while calling CNI plugins. Therefore, reachability is a bit specific to Kubernetes networking requirements.\nThe purpose of the reachability is ensuring every Pod is accessible from every node. So, it\u0026rsquo;s a bit related to route lifecycle; thus, we should somehow announce the routes to each pod to each node. Therefore, Kubernetes CNI solutions ship with the \u0026lsquo;daemon\u0026rsquo; running on each node to ensure that the network is configured in a way that all Pods are accessible across nodes.\nHow could we make it possible? As we mentioned in previous section, if nodes are in the same L2 network, we could utilize Switch + Routers. But the common ways to solve this are \u0026lsquo;Overlay Networks\u0026rsquo; (e.g, VXLAN or IP-in-IP) or \u0026lsquo;Routing Protocols\u0026rsquo; (BGP or OSPF).\nThere might be other hacky solutions as well; but these are the most common ones I faced.\nHow CNI Plugins Called The CNI (Container Network Interface) specification defines how a container runtime, like Kubernetes, interacts with network plugins. This guide covers the fundamental operations and concepts you need to know. If you are looking for more details, please take a look at the actual specification (https://github.com/containernetworking/cni/blob/main/SPEC.md).\nA runtime calls a CNI plugin by providing two key inputs: a JSON network configuration (via STDIN) and a set of environment variables.\nNetwork Configuration File The runtime finds network configurations by searching a dedicated directory, typically /etc/cni/net.d. Kubernetes, for example, monitors this directory periodically for configuration files. This directory can be configured; therefore, in your cluster, it might be located somewhere else.\nThis JSON file contains settings for the runtime and for any plugins it needs to call, such as bridge or ipam.\nHere is an example of a simple network configuration:\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;cniVersion\u0026#34;: \u0026#34;1.1.0\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;isDefaultGateway\u0026#34;: true, \u0026#34;ipMasq\u0026#34;: true, \u0026#34;ipam\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;host-local\u0026#34;, \u0026#34;subnet\u0026#34;: \u0026#34;10.244.0.0/24\u0026#34; } } When the runtime reads this file, it identifies the main plugin to run from the \u0026ldquo;type\u0026rdquo; field. In this case, it\u0026rsquo;s bridge. The runtime will then look for an executable file named bridge in its plugin search path (usually /opt/cni/bin).\nIt is critical that network configuration files remain static while in use. CNI operations are not designed to handle configuration changes between an ADD and a DEL command.\nFor example, assume your configuration uses CIDR-A when a pod is created. If you modify the file to use CIDR-B before that pod is deleted, the CNI plugin will not know about the original CIDR-A. This will likely cause the plugin to fail when it tries to clean up the old network interfaces during the DEL operation.\nCNI Operations The JSON configuration defines what the network should look like, but it doesn\u0026rsquo;t specify what to do. The runtime tells the plugin which action to perform by setting environment variables.\nThe most important variable is CNI_COMMAND, which defines the operation:\nADD: Add container to network, or apply modifications DEL: Remove container from network, or un-apply modifications CHECK: Check container\u0026rsquo;s networking is as expected STATUS: Check plugin status VERSION: probe plugin version support GC: Clean up any stale resources Reference CNI spec\nOther variables provide the context for the command:\nCNI_NETNS: A path to the network namespace (e.g, /var/run/netns/{ns}) CNI_IFNAME: Interface name to create \u0026lsquo;inside\u0026rsquo; the container. CNI_PATH: List of paths in the system to search CNI plugin executables. CNI_CONTAINERID: Container ID for the container. CNI_ARGS: Extra args provided by runtime. Example: An ADD Operation Let\u0026rsquo;s put this all together. Imagine we want to add a container with ID c123 to the network namespace container0, using the configuration file /etc/cni/net.d/10-mynet.conflist (which contains our JSON example).\nThe runtime would execute a command similar to this:\n1 2 3 4 5 6 7 8 9 10 # runtimes get these information via # Network configuration JSON. PLUGIN_NAME=\u0026#34;bridge\u0026#34; CNI_PATH=\u0026#34;/opt/cni/bin\u0026#34; CNI_COMMAND=\u0026#34;ADD\u0026#34; \\ CNI_CONTAINERID=\u0026#34;c123\u0026#34; \\ CNI_NETNS=\u0026#34;/var/run/netns/container0\u0026#34; \\ CNI_IFNAME=\u0026#34;eth0\u0026#34; \\ cat /etc/cni/net.d/10-mynet.conflist | $CNI_PATH/$PLUGIN_NAME In this command, the runtime pipes the JSON configuration to the bridge plugin\u0026rsquo;s STDIN and sets the environment variables. The bridge plugin executes and reads the config.\nIf you remember our quick demo, this configuration instructs the bash commands we run to:\nCreate eth0 interface in container (instead of c0-veth) The network namespace you need to operate is container0, which means that ip netns exec \u0026lt;given_namespace\u0026gt; $operations You may also see CNI_NETNS_OVERRIDE. This variable is not part of the official CNI spec but is used by the libcni Go package. It acts as a guard-rail to stop the plugin from modifying the wrong network namespace if the namespace path changes unexpectedly during the operation. This should ideally not happen with modern container runtimes, as they do not rely on process ID based paths for network namespaces.\nhttps://github.com/containernetworking/plugins/issues/714\nKubernetes and CNI But how does Kubernetes use CNI? We mentioned that we may have multiple \u0026ldquo;plugins\u0026rdquo; available. We should somehow instruct Kubernetes to use correct plugins.\nKubernetes manages Pods with CRI (Container Runtime Interface), which is triggered by kubelet. So, kubelet calls CRI via gRPC API, and your cluster can use various CRI implementations (RPC implementation). While setting up a Pod, kubelet calls \u0026ldquo;rpc RunPodSandbox(RunPodSandboxRequest)\u0026rdquo;, which in turn calls underlying CRI. While CRI is setting up the Pod, it internally calls CNI to make sure that Pod\u0026rsquo;s network environment is ready. That\u0026rsquo;s actually how Kubernetes calls CNI. It\u0026rsquo;s a bit of a chain of calls but to simply put: kubelet -\u0026gt; CRI -\u0026gt; CNI\nFor example, how container-d calls CNI in RunPodSandbox: https://github.com/containerd/containerd/blob/1c4457e00facac03ce1d75f7b6777a7a851e5c41/internal/cri/server/sandbox_run.go#L261-L263\nCRI (Container Runtime Interface) calls CNI to set up the pod network, by following the above example. Then, based on CNI configurations and arguments, the CNI performs operations to set up the pod network.\nWriting CNI Plugin in Go The \u0026ldquo;bridge\u0026rdquo; demo we created is actually quite close to being a CNI plugin. We just need to make it aware of the CNI environment variables (like CNI_COMMAND) and make it read from STDIN and write to STDOUT, as defined in the CNI specification. However, if you\u0026rsquo;ve ever checked the official plugins, they are usually not shell scripts. We need to handle JSON, error reporting, and complex networking operations, which is a better job for a language like Go.\nThis section will go through my notes on what I learned from the official \u0026ldquo;bridge\u0026rdquo; plugin while writing my own.\nThe source code for the CNI maintained \u0026ldquo;bridge\u0026rdquo; plugin: https://github.com/containernetworking/plugins/tree/v1.8.0/plugins/main/bridge\nCNI maintainers provide official Go packages to handle the common boilerplate. This includes reading CNI environment variables, parsing the network configuration from STDIN, validating them, and formatting the result as JSON to STDOUT. Building all of this from scratch would be tedious.\nThe libcni package (https://pkg.go.dev/github.com/containernetworking/cni/libcni) and especially the skel package (https://pkg.go.dev/github.com/containernetworking/cni/pkg/skel) are designed to solve this.\nThe skel package provides a skeleton for a CNI plugin. It implements all the argument parsing and validation, like checking if all required environment variables are defined for a given CNI_COMMAND.\nhttps://github.com/containernetworking/plugins/blob/0e648479e11c2c6d9109b14fc0c9ac64c677861b/plugins/main/bridge/bridge.go#L837-L843\n1 2 3 4 5 6 7 8 func main() { skel.PluginMainFuncs(skel.CNIFuncs{ Add: cmdAdd, Check: cmdCheck, Del: cmdDel, Status: cmdStatus, }, version.All, bv.BuildString(\u0026#34;bridge\u0026#34;)) } As a plugin developer, you just register your functions for the Add, Check, and Del commands. The skel package handles calling the right function and provides a struct containing all the parsed arguments and network configuration. The rest is just implementing the networking logic based on the provided information.\nLet\u0026rsquo;s skip the configuration parsing and dive into a Go-specific trick you\u0026rsquo;ll need.\nGo Scheduler and the Problem One thing I realized is that most CNI plugins use runtime.LockOSThread() before they change network namespaces. This isn\u0026rsquo;t a function I use in my typical day-to-day work. Understanding why this is necessary led me to learn much more about how Go\u0026rsquo;s scheduler works with OS threads.\nThe Go scheduler\u0026rsquo;s job is to run these N goroutines on M OS threads (this is called an M:N scheduler).\nGOMAXPROCS limits the number of OS threads that can execute user-level Go code simultaneously. By default, this is set to the number of available CPU cores. Note that Go can create additional OS threads beyond this limit when threads block on system calls, but those blocked threads don\u0026rsquo;t count against the GOMAXPROCS limit. Only threads actively executing Go code are constrained by GOMAXPROCS.\nThe Go scheduler maintains multiple runqueues to manage goroutines efficiently. There is a global runqueue shared by all threads, and each thread has its own local runqueue. This design minimizes lock contention. When a thread needs work, it first checks its local queue, and if empty, it can steal work from other threads\u0026rsquo; queues or check the global queue.\nThe Go scheduler uses asynchronous preemption. This means that if a goroutine runs for too long (e.g., more than 10ms), the scheduler can forcefully pause it and schedule it to run again later. This is great for fairness, as it prevents one CPU-heavy goroutine from starving all others.\nFor example, if you have a goroutine that blocks the CPU and not being able to voluntarily give up its control to CPU back (due to some maybe hardware flaw), then other goroutines in the OS thread\u0026rsquo;s runqueue needs to wait for this long running to finish.\nThis preemption has a critical side effect: a goroutine is not guaranteed to stay on the same OS thread. It might run on Thread 1, get preempted, and later resume its work on Thread 2. For most code, this doesn\u0026rsquo;t matter. But for a CNI plugin, it\u0026rsquo;s a huge problem.\nIssues with Go and Network Namespaces You might be wondering, \u0026ldquo;What does this have to do with CNI?\u0026rdquo;. The problem lies in how we change network namespaces.\nWhen we create a network namespace for a pod, we need to run commands inside it. We don\u0026rsquo;t use the ip netns exec command; instead, we use a Linux system call: setns(2) under the hood.\nThe setns(2) syscall is very specific: it changes the namespace of the calling thread, not the whole process. So, this Linux system call associates a thread with a namespace, not a process with a namespace. In Go, this might be a bit problematic due to Go scheduler behavior.\nGo scheduler can preempt the goroutine and move it to another OS thread, due to motivations explained in the previous section. For example, assume that cmdAdd goroutine is running on OS Thread A (which is in the host netns). The goroutine calls setns() to enter the pod\u0026rsquo;s netns, which changes OS Thread A\u0026rsquo;s state. Now, the thread is in the pod\u0026rsquo;s network namespace. Your goroutine continues, preparing to create the veth pair. BAM! The Go scheduler preempts your goroutine because your time is up, the turn is for the next scheduled goroutine. A moment later, the scheduler decides to resume your goroutine. It picks OS Thread B (which is still in the host netns) to run it. Your goroutine, unaware it has been moved, continues where it left off. It tries to create the veth pair, but it\u0026rsquo;s now running on OS Thread B, so it incorrectly modifies the host network instead of the pod\u0026rsquo;s network. This is a subtle and dangerous bug :(.\ngoroutine -\u0026gt; OS Thread A (namespace: host) | | (preemption, goscheduler moves goroutine to the new thread) v OS Thread B (namespace: somethingelse) Solution: runtime.LockOSThread() This is precisely what runtime.LockOSThread() solves.\nWhen you call runtime.LockOSThread(), you are telling the Go scheduler: \u0026ldquo;Pin this current goroutine to the current OS thread\u0026rdquo;. It does not stop the scheduler. Your goroutine can still be preempted. But when the scheduler resumes it, it is forced to resume it on the exact same OS thread it was pinned to. When we lock the thread, it also prevents the Go scheduler from running other goroutines on that thread. This is useful if your goroutine modifies the thread\u0026rsquo;s namespace state (like network namespace operations). It ensures that no other goroutine that might also try to update thread state (like changing the network namespace) gets scheduled on that thread.\nFor example, when a goroutine calls runtime.LockOSThread(), it is now pinned to OS Thread A. When this goroutine running on Thread A enters the pod network namespace and gets preempted, the scheduler will resume the goroutine on the same OS Thread A. In the meantime, no other goroutines will be scheduled on that thread.\nThis is why you see most of the namespace-switching logic in CNI plugins using a LockOSThread/UnlockOSThread block.\nhttps://github.com/containernetworking/plugins/blob/372953dfb89fe5c17a29a865b502a2eabb31a195/pkg/ns/ns_linux.go#L27-L35\nOne final remark is that this thread lock is not inherited by new goroutines. If you spawn a new goroutine from your locked one, the new goroutine can run on any thread.\n1 2 3 4 5 runtime.LockOSThread() defer runtime.UnlockOSThread() go func() { // this new goroutine may run on a different thread }() Therefore, do not spawn a new goroutine from a locked one if the new goroutine is expected to run on the same thread.\nLockOSThread() works like a taint. If you do not unlock the thread, the thread will not be used for scheduling other goroutines anymore. When the locked goroutine exits without unlocking, the thread itself will be terminated. So, do not forget to unlock the thread (unless you know what you are doing) to return it to the scheduler pool.\nTo obtain the current ns of the thread, you can simply use /proc/${os.getPid()}/task/${unix.Gettid()}/ns/net\nBridge Plugin The official Bridge plugin roughly performs the following operations:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 br, brInterface, err := setupBridge(n) // ... netns, err := ns.GetNS(args.Netns) // ... hostInterface, containerInterface, err := setupVeth(netns, br, args.IfName) // run IPAM plugin for IP assignment ipam.ExecAdd(n.IPAM.Type, args.StdinData) netns.Do(func(_ ns.NetNS) error { // Add the IP to the interface return ipam.ConfigureIface(args.IfName, result) }, ) // ... // add IP to bridge as well. err = ensureAddr(br, \u0026amp;gw) So, what we are doing is as follows:\nsetup bridge setup veth pairs run IPAM plugin and configure veth and bridge to ensure they have IP How does it create links (devices)? For that, it uses https://github.com/vishvananda/netlink package which is an API to perform operations similar to ip link add by communicating with the kernel. And this package is the Go binding of this kernel communication.\nThe Do method is quite powerful method, which is defined as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 type NetNS interface { // Executes the passed closure in this object\u0026#39;s network namespace, // attempting to restore the original namespace before returning. // However, since each OS thread can have a different network namespace, // and Go\u0026#39;s thread scheduling is highly variable, callers cannot // guarantee any specific namespace is set unless operations that // require that namespace are wrapped with Do(). Also, no code called // from Do() should call runtime.UnlockOSThread(), or the risk // of executing code in an incorrect namespace will be greater. See // https://github.com/golang/go/wiki/LockOSThread for further details. Do(toRun func(NetNS) error) error // ... other methods } https://github.com/containernetworking/plugins/blob/0e648479e11c2c6d9109b14fc0c9ac64c677861b/pkg/ns/ns_linux.go#L74-L83\nIt is a powerful method that achieves what we are looking for. It locks the thread, runs our Go code in that thread to safely manipulate the thread, and takes the network namespace where the operation has started (like host).\nSo, Do ensures the user operation is safe by locking the goroutine to a specific OS thread, performing the namespace switch, running the code, and carefully switching back.\nNote: The following is a simplified, pseudocode representation of Do method. It omits error handling, handle closing (.Close()), and other details to focus purely on the core logic and execution flow.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 // Do executes the \u0026#39;toRun\u0026#39; function within the network namespace \u0026#39;ns\u0026#39;. func (ns *netNS) Do(toRun func(hostNS NetNS)) { // Check if the target namespace handle \u0026#39;ns\u0026#39; is already closed. if err := ns.errorIfClosed(); err != nil { return err } // Get a handle to the current (host) namespace before we do anything. // This \u0026#39;hostNS\u0026#39; handle is what we\u0026#39;ll pass to the user\u0026#39;s function. // So that if user needs to perform operations in the initial network namespace // it can use this `hostNS` to checkout to the correct network namespace. hostNS := getCurrentNS() // We need a WaitGroup to wait for the goroutine to finish. var wg sync.WaitGroup wg.Add(1) var innerError error go func() { defer wg.Done() // Lock this goroutine to its current OS thread, as discussed runtime.LockOSThread() // Get a handle to this specific thread\u0026#39;s original namespace. threadOriginalNS := getCurrentNS() // Switch to the target namespace, like `netns(2)` system call. // this will affect the thread\u0026#39;s state. ns.Set() defer func() { // Switch back to the thread\u0026#39;s original namespace. switchBackErr := threadOriginalNS.Set() // - ONLY unlock the OS thread if we successfully switched back. // - If \u0026#39;switchBackErr\u0026#39; is not nil, we are in a bad state. // - We leave the thread locked. The Go runtime will see // this and discard the OS thread entirely, preventing // a \u0026#34;dirty\u0026#34; thread (stuck in the wrong ns) from // being reused by the scheduler, as explained in the prev section. if switchBackErr == nil { runtime.UnlockOSThread() } }() // Now that we are inside the target namespace \u0026#39;ns\u0026#39;, execute the user\u0026#39;s function. innerError = toRun(hostNS) }() wg.Wait() return innerError } This is quite useful, especially while setting up veth pairs.\nIf you remember, we were running ip commands in both host and container namespaces while setting up the veth pairs. With this Do method, we can actually achieve something similar. The following is the pseudocode for \u0026ldquo;bridge\u0026rdquo; plugin while setting up the veth pairs.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // - First, obtain CNI_IFNAME and CNI_NETNS to understand // what interface name should be created in which container namespace. // These are embedded in the `args` struct, which is initialized by `skel` boilerplate // from `libcni` package. // - And then, in host namespace, checkout the container namespace // which is created by runtime (k8s). // - Then, use Do method to perform operations required to create veth pairs. containerNs, _ := ns.GetNS(args.Netns) defer netns.Close() // Note that we run this code in the host namespace. // That\u0026#39;s why the argument in caller is \u0026#39;hostNs\u0026#39;. // By using the Do function, we run the operations in containerNs with locked OS thread. containerNs.Do(func(hostNs ns.NetNS) error { // The operations in this caller is running in the `containerNs`. // First create a veth device. veth:= netlink.Veth{ LinkAttrs: netlink.LinkAttrs{Name: args.Ifname}, PeerName: hostVethPeerName, // - PeerNamespace is the interface of the peer (host). // - It can take the namespace as FD (file descriptor), // or PID (process ID) for the namespace. // - Since the file descriptor approach is the convenient one, // as explained with CNI_NETNS_OVERRIDE above, // use helpers of `ns.NetNS` struct to obtain file descriptor // of the host network namespace. // - Since the veth pair that we create here is going to be located // in the container its peer needs to be in host, // so that we can connect to it to the bridge. PeerNamespace: netlink.NsFd(int(hostNs.Fd())) /*...*/ } // Then, `add` this link device; similar to `ip link add` netlink.LinkAdd(\u0026amp;veth) // Set this new link device `up`, similar to `ip link set up` netlink.LinkSetUp(netlink.LinkByName(args.Ifname)) // Now, run the following code in \u0026#34;host\u0026#34; namespace. hostNs.Do(func(_ ns.NetNS) error { // Set the veth pair in the host namespace UP. hostVeth, _ := netlinksafe.LinkByName(hostVethPeer) netlink.LinkSetUp(hostVeth) return nil }) }) Kernel Knobs The official \u0026ldquo;bridge\u0026rdquo; plugin uses more kernel knobs that we see so far. We only saw \u0026ldquo;ip_forward\u0026rdquo; but the official plugin uses more than that to provide better experience the users. This section will go through some of them that I noticed to mention.\n/net/ipv4/conf/\u0026lt;interface\u0026gt;/arp-notify This knob controls Gratuitous ARP (GARP) behavior when the interface\u0026rsquo;s state becomes UP. A Gratuitous ARP is a broadcast packet where a host announces its own IP-to-MAC mapping, in order to update the caches of other devices on the same network. By default (0), the kernel does not send a GARP when an interface comes up. When enabled (1), the kernel will send GARP packets when this interface is brought to an UP state or when an IPv4 address is added to it.\nThis setting directly addresses the problem of stale ARP caches on peer devices. Especially in high-availability (HA) or IP failover scenarios, such as a Kubernetes VIP moving between nodes, a client\u0026rsquo;s ARP cache may still point to the MAC address of the old, failed node. This creates issues until that client\u0026rsquo;s ARP entry times out.\nEnabling arp_notify solves this by having the kernel proactively announce the new \u0026ldquo;IP-to-MAC\u0026rdquo; mapping. For ex, when a standby node\u0026rsquo;s interface comes UP to take over a VIP, the arp_notify mechanism triggers a GARP, forcing all listeners on the L2 segment to immediately update their ARP caches. This preempts the cache timeout and makes the failover near-instantaneous.\n/net/ipv6/conf/\u0026lt;interface\u0026gt;/keep_addr_on_down This configuration prevents the kernel from flushing static global IPv6 addresses when an interface\u0026rsquo;s link state goes DOWN. This is a critical difference from IPv4, where addresses are retained by default.\nWith the default setting (0), the kernel flushes all global IPv6 addresses when the link state goes DOWN. By setting this knob to 1, the kernel preserves the IPv6 address during the link-down event.\nMulti-Node reachability Besides from the implementation-wise differences, the official \u0026ldquo;bridge\u0026rdquo; plugin in Go is similar to what we have built. We\u0026rsquo;ve walked through the logic of building a CNI plugin, from using CNI Go packages to safely managing network namespaces with LockOSThread. We have a complete solution for local pod connectivity. Our plugin can successfully get a cmdAdd call, create a veth pair, connect a pod to the host\u0026rsquo;s bridge, and get it an IP address. This setup works perfectly for any pods that need to communicate on the same node.\nBut what happens when Pod A on Node 1 tries to send a packet to Pod B on Node 2? As we\u0026rsquo;ve established, our bridge plugin alone can\u0026rsquo;t solve this. The packet gets sent to the cni0 bridge and then dropped by the host, which has no route to the other node\u0026rsquo;s pod network.\nThis is the central challenge of Kubernetes networking: multi-node reachability. Since the CNI specification itself only covers \u0026lsquo;connectivity\u0026rsquo;, it\u0026rsquo;s up to the CNI daemon to solve this. This next section will explore the common strategies used to make this cluster-wide communication possible.\nLet\u0026rsquo;s first see why the \u0026lsquo;bridge\u0026rsquo; approach that we explained and developed does not provide reachability in multi-node Kubernetes clusters.\nThe bridge plugin (like the cni0 bridge it creates) is a purely host-specific construct. The cni0 virtual switch on Node 1 is completely separate from the cni0 virtual switch on Node 2. They have no knowledge of each other and are not connected in any way. Think of it like two switches located in two networks having two switches respectively. You cannot expect a switch on one network to communicate with the switch on the other without extra configuration.\nThis separation creates a \u0026ldquo;reachability\u0026rdquo; problem.\nFor example, consider when Pod A on Node 1 (10.244.1.5) tries to send a packet to Pod B on Node 2 (10.244.2.8):\nThe packet leaves Pod A and arrives at the cni0 bridge on Node 1. The bridge inspects the destination (10.244.2.8) and finds it isn\u0026rsquo;t connected to any of its local pod interfaces, as it only knows about its own 10.244.1.x pods. The packet is then passed up to the host, Node 1. However, Node 1\u0026rsquo;s kernel also has no route for the 10.244.2.0/24 subnet; it has no idea that this network \u0026ldquo;lives\u0026rdquo; on Node 2, thus the packet is unroutable and dropped. This is precisely the problem that the CNI daemon (the second component we discussed) is designed to solve. Its entire job is to create the \u0026ldquo;routes\u0026rdquo; that Node 1 is missing, making Node 2\u0026rsquo;s pods reachable. The strategy this daemon uses depends entirely on the underlying physical network. We will now explore the three most common strategies for solving this multi-node reachability problem.\nBroadly, your cluster\u0026rsquo;s nodes live in one of two physical network scenarios\nNodes are on the same L2 Network: This means all your nodes are in the same subnet (e.g., all have IPs like 192.168.1.x). They can find and send packets to each other directly, like computers plugged into the same home router. So, no routing is needed.\nNodes are on different L2 Networks: This is the most common scenario. Your nodes are in different subnets (e.g., 192.168.1.x and 192.168.2.x, or in different Availability Zones). They cannot reach each other directly and must send packets through at least one router. So, routing is needed.\nThese two network designs require completely different solutions to make pods reachable. We will now explore the three most common strategies, though there are different solutions as well.\nSimple Routing in Same Subnet This is a straightforward approach that works only when the nodes are on the same L2 network. The CNI daemon on each node acts as a controller, watching the Kubernetes API. When a new node joins the cluster, the daemon on every other node gets an update.\nFor example, when Node 2 joins, the CNI daemon on Node 1 sees the new Node 2 object. It reads two key pieces of information: Node 2\u0026rsquo;s IP (e.g., 192.168.1.11) and the pod network assigned to it, known as its podCIDR (e.g., 10.244.2.0/24). The daemon then adds a route to Node 1\u0026rsquo;s local routing table, typically using a netlink library, such as ip route add 10.244.2.0/24 via 192.168.1.11. Now, when Pod A on Node 1 sends a packet to Pod B (10.244.2.5), Node 1\u0026rsquo;s kernel sees this route and knows to forward the packet directly to Node 2\u0026rsquo;s IP. This is very high-performance because there is no encapsulation.\nWe\u0026rsquo;ll develop an example controller to perform this as well.\nDynamic Routing Protocols These protocols allow configuring routers to exchange route information between each other. BGP is one of the popular protocol used for this.\nBGP, in general, forms neighourship across routers, where neighbourship is declared statically. Once you register your peers, routing information is shared across routers, through a TCP connection.\nIn Kubernetes, this usually works by having the CNI daemon on each node run a lightweight BGP agent. This agent \u0026ldquo;peers\u0026rdquo; (forms a BGP neighborship). Calico is a famous CNI plugin that supports BGP.\nThis is quite useful because if you have multiple large clusters, you can use BGP or something similar to achieve route sharing across your cluster\u0026rsquo;s outer router. The routers are all taught where the pod networks are. Although this is a very powerful and scalable solution, it\u0026rsquo;s also the most complex. It requires access to and expertise in configuring your physical network fabric (your routers and switches) to peer with your nodes, which may not be possible all the time.\nOverlay Networks An overlay network is a virtual network built on top of an existing physical network, like a cloud provider\u0026rsquo;s network. This concept isn\u0026rsquo;t specific to Kubernetes but very useful in managed Kubernetes offerings, because your cluster nodes (like VMs) might be on different underlying networks, such as in different cloud availability zones.\nIn modern data centers or clouds, your cluster nodes (VMs) are often in different locations. They might be on different racks or even in different \u0026ldquo;availability zones\u0026rdquo;. They are not all plugged into one giant switch, instead they live on a complex, routed network.\nThis creates a problem: the physical network only knows how to send packets between nodes (using node IPs). It has no idea what a pod IP is or how to find it. So, even though nodes are connected by L3 connectivity, each nodes get its own subnet. Assume that Node 1 and Node 2 are VMs located in different servers and if Node 1 just sent a packet addressed to Pod IP located in Node 2, the physical network would drop it, not knowing where to send it even though Node 1 and Node 2 can communicate with each other (L3 connectivity).\nTo solve this, the overlay network hides the original pod packet. It does this by \u0026ldquo;wrapping\u0026rdquo; it inside a new, \u0026ldquo;outer\u0026rdquo; packet. This process is called encapsulation. The new outer packet is addressed to the node that the pod lives on (e.g., Node 2\u0026rsquo;s IP), which the physical network does understand.\nOne of the most common overlay networking technique is VXLAN (Virtual Extensible LAN) which uses the similar idea of wrapping packets. Each node has a virtual device called VTEP (Virtual Tunnel Endpoint), where packets are sent to this tunnel endpoint before they are going into other nodes.\nFor example, assume that we have Pod A on Node 1 and Pod B on Node 2. When Pod A on Node 1 sends a packet to Pod B, the packet targets Pod B\u0026rsquo;s IP address. The kernel recognizes that this Pod is not in our subnet, so the packet is destined to VTEP, because since Pod B\u0026rsquo;s IP address is local to Node 2, if the physical network receives it, it does not know how to send it to the actual place (similar to NAT problem).\nThe VTEP encapsulates this packet inside a new UDP packet, which is destined to Node 2\u0026rsquo;s IP.\n+-----------------------------------------------------+ | Outer IP Header (Source: Node 1, Dest: Node 2) | +-----------------------------------------------------+ | Outer UDP Header (Dest Port: 4789 for VXLAN) | +-----------------------------------------------------+ | VXLAN Header (VNI) | +-----------------------------------------------------+ | +---------------------------------------------+ | | | Inner IP Header (Source: Pod A, Dest: Pod B)| | | +---------------------------------------------+ | | | Payload (Data) | | | +---------------------------------------------+ | +-----------------------------------------------------+ Note: This is a simplified diagram. A real packet would also include L2 (Ethernet) headers for both the inner and outer packets, as well as a specific VXLAN header. But this illustrates the main idea of wrapping the pod-to-pod packet inside a node-to-node packet.\nThe physical network sees a normal UDP packet from Node 1 to Node 2 and routes it. Node 2\u0026rsquo;s kernel receives the UDP packet, sees it\u0026rsquo;s for VXLAN, and hands it to its VTEP. The VTEP de-encapsulates it, removing the outer UDP packet and what\u0026rsquo;s left is the original packet addressed to Pod B. Since Node 2 knows that the Pod B is on its system, it delivers it.\nThis is a popular approach in most cloud providers because it decouples the pod network from the physical network. It allows Kubernetes to create its own flat, virtual network for pods without having to ask the cloud provider to make any special changes to its physical routers. As long as the nodes can send UDP packets (L3 connectivity) to each other, the pod network just works.\nWriting CNI Daemon in Go Finally, in this section, we are going to write a simple daemon utilizing the principles defined in the Routing in Same Subnet section. We\u0026rsquo;ll create a Kubernetes controller that modifies each node\u0026rsquo;s route table to ensure networking works as expected.\nOur controller will run as a DaemonSet, meaning one copy (one pod) will run on each node in the cluster. This daemon watches for changes to Node objects. Its job is to ensure that the correct routes are set up on the host it\u0026rsquo;s running on.\nIt adds a route for every other node in the cluster, telling the host\u0026rsquo;s kernel: \u0026ldquo;To reach pods on Node B (with PodCIDR 10.244.1.0/24), send the traffic directly to Node B\u0026rsquo;s internal IP (e.g., 192.168.1.101).\u0026rdquo;\nHow Can a Pod Change the Host\u0026rsquo;s Routes? Before we look at the Go code, we should understand how a pod, which is normally an isolated sandbox, is allowed to modify its host. Our DaemonSet\u0026rsquo;s pod needs several high-privilege settings:\nhostNetwork: true: This is the most important setting. It tells Kubernetes to not create a separate network namespace for this pod. The pod will run directly in the host\u0026rsquo;s network namespace. This gives our controller access to the host\u0026rsquo;s eth0 and, crucially, its main routing table. NET_ADMIN Capability: Even in the host\u0026rsquo;s namespace, a process needs permission to change network settings. This capability grants our controller the right to add and delete routes. priorityClassName: system-node-critical: This is a best practice for CNIs. It tells Kubernetes this pod is essential for the node to function, so it should be scheduled first and be the last to get evicted if the node is under resource pressure. tolerations: - operator: Exists: This ensures our DaemonSet pod will run on all nodes, including control-plane nodes that might have taints. This is necessary for full cluster connectivity. You may also see an initContainer in CNI DaemonSets. This init container often has privileged: true and mounts hostPath volumes for /opt/cni/bin and /etc/cni/net.d. Its job is different: it\u0026rsquo;s responsible for installing the CNI plugin binary (like our bridge plugin) onto the host\u0026rsquo;s filesystem, so the kubelet can call it.\nController Note: The following is a simplified pseudocode representation. It omits error handling, logging, and other production-level details to focus purely on the core logic and execution flow. The source code can be found here for reference: https://github.com/buraksekili/hirs-cni/blob/main/cmd/controllers/node/main.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 func main() { currentNodeName := os.Getenv(\u0026#34;NODE_NAME\u0026#34;) mgr := CreateControllerManager() reconciler := \u0026amp;NodeReconciler{ Client: mgr.GetClient(), NodeName: currentNodeName, } // Set up the controller with the manager. // - We watch for \u0026#34;Node\u0026#34; objects. // - We filter out events for our *own* node, // since we don\u0026#39;t need to add a route to ourselves. isRemoteNode := predicate.NewPredicateFuncs(func(obj client.Object) bool { return obj.GetName() != r.NodeName }) ctrl.NewControllerManagedBy(mgr). For(\u0026amp;corev1.Node{}). WithEventFilter(predicate.Filter(isRemoteNode)). Complete(reconciler) mgr.Start() } func (r *NodeReconciler) Reconcile(ctx, req) { // We already filtered out our own node, so this is always a remote node. node := r.Get(ctx, req.NamespacedName) if node.IsBeingDeleted() { if controllerutil.ContainsFinalizer(node, \u0026#34;hirscni.io/route-cleanup\u0026#34;) { r.deleteRoute(node) controllerutil.RemoveFinalizer(node, \u0026#34;hirscni.io/route-cleanup\u0026#34;) return r.Update(ctx, node) } return } // add finalizer if it does not exist. if controllerutil.AddFinalizer(node, \u0026#34;hirscni.io/route-cleanup\u0026#34;) { r.Update(ctx, node) return } return r.reconcileRoute(ctx, node) } func (r *NodeReconciler) reconcileRoute(ctx, node) { podCIDR := node.Spec.PodCIDR if podCIDR == \u0026#34;\u0026#34; { return } // Get that node\u0026#39;s internal IP (e.g., \u0026#34;192.168.1.101\u0026#34;). nodeInternalIP := getNodeInternalIP(node) if nodeInternalIP == \u0026#34;\u0026#34; { return } r.addOrUpdateRoute(podCIDR, nodeInternalIP) } func (r *NodeReconciler) addOrUpdateRoute(podCIDR, gatewayIP) { // Parse the destination CIDR. dst := net.ParseCIDR(podCIDR) // Parse the gateway (the remote node\u0026#39;s) IP. gw := net.ParseIP(gatewayIP) // Find the local interface (link) to reach that gateway. // If you remember, we were using `ip route get \u0026lt;address\u0026gt;` command // to see which route the host takes while reaching \u0026lt;address\u0026gt;. // `netlink.RouteGet` runs a similar request. routes := netlink.RouteGet(gw) linkIndex := routes[0].LinkIndex // The following route means that, to reach the address `dst`, // forward the packet to `gw` through `linkIndex` device. route := \u0026amp;netlink.Route{ LinkIndex: linkIndex, // e.g., \u0026#39;eth0\u0026#39; Dst: dst, // e.g., 10.244.1.0/24 Gw: gw, // e.g., 192.168.1.101 } // just a tip: `ip route replace` is the idempotent call // to manage routes. netlink.RouteReplace(route) } func (r *NodeReconciler) deleteRoute(node) { podCIDR := node.Spec.PodCIDR nodeInternalIP := getNodeInternalIP(node) dst := net.ParseCIDR(podCIDR) gw := net.ParseIP(nodeInternalIP) routes := netlink.RouteGet(gw) linkIndex := routes[0].LinkIndex route := \u0026amp;netlink.Route{ LinkIndex: linkIndex, Dst: dst, Gw: gw, } netlink.RouteDel(route) } func getNodeInternalIP(node) string { // Loop through the node\u0026#39;s addresses and find the one labeled \u0026#34;InternalIP\u0026#34; for _, addr := range node.Status.Addresses { if addr.Type == corev1.NodeInternalIP { return addr.Address } } return \u0026#34;\u0026#34; } Conclusion We\u0026rsquo;ve covered a lot of ground in this post. We started with the very basics of networking theory, then saw how those ideas are implemented in Linux with tools like network namespaces, veth pairs, and bridges.\nFrom that foundation, we explored the CNI specification and wrote our own CNI plugin in Go, even tackling tricky concurrency issues like runtime.LockOSThread. We also learned that a plugin is only half the story and went on to build a complete CNI daemon as a Kubernetes controller, teaching it to manage routes across multiple nodes.\nWhile we\u0026rsquo;ve built a functional CNI, the Kubernetes networking world is vast. We didn\u0026rsquo;t get to critical features like Network Policy (for security), Service Routing (for ClusterIPs), or IP Address Management (IPAM).\nI hope this journey has helped demystify what\u0026rsquo;s happening under the hood. The next time you deploy a pod and see it instantly get an IP, you\u0026rsquo;ll know the whole story, from the kubelet calling the plugin for local connectivity, to the CNI daemon ensuring that pod is reachable by the rest of the cluster.\nAs I mentioned, this is all based on my personal notes. If you find any mistakes or have suggestions, feel free to edit this post through GitHub and raise a PR or contact me via X.\nReferences Go Scheduler Kubernetes and the CNI: Where We Are and What\u0026rsquo;s Next - Casey Callendrello, CoreOS Linux Namespaces and Go Don\u0026rsquo;t Mix Linux Namespaces Part 4 Namespaces in Operation, part 4: more on PID namespaces Networking and Kubernetes: A Layered Approach Runtime Package Documentation Tutorial: Communication Is Key - Understanding Kubernetes Networking - Jeff Poole, Vivint Smart Home ","permalink":"https://buraksekili.github.io/articles/cni/","summary":"\u003cp\u003eThis blog post is a collection of my personal notes on networking. For a long time, I had to jump between different notebooks to connect concepts; from core networking theory, to Linux internals, all the way up to Kubernetes and CNI.\nThis post is my attempt to combine all those notes into a single, logical document.\u003c/p\u003e\n\u003cp\u003eWe\u0026rsquo;ll follow a step-by-step path. We\u0026rsquo;ll start with fundamental network concepts, then see how those are implemented in Linux, which is the foundation for most modern virtual networking.\nFinally, we\u0026rsquo;ll see how Kubernetes builds on top of it all.\u003c/p\u003e","title":"Let's Build a CNI Plugin! From Linux Networking to CNI"},{"content":"I\u0026rsquo;ve always found the best way to learn something is to try and write it down. This post is the result of that process, a collection of my personal notes (zettelkasten) aimed at connecting the dots between three fundamental concepts in Linux: inodes, file descriptors, and sockets. So, this post is just a cleaned-up version of my personal notes, explaining how inodes (representing files on disk), file descriptors (used by programs), and sockets (for network communication) all fit together.\ni-nodes Every file and directory in a filesystem is represented by a data structure called an inode. The inode stores metadata about the object, such as its permissions, attributes, and the disk block locations of its data. In essence, an inode contains pointers to the actual data blocks on the disk, along with the file attributes.\nThis is an overly simplified reference of the inode table and data blocks. In real scenarios, since a file can be larger than a single disk block (typically 4KB or 8KB), the inode stores a series of pointers to all the data blocks that constitute the file. This allows the system to assemble the complete file from its scattered blocks.\nAn inode also includes a reference count, which tracks the number of links pointing to it. When you create a link to a file, the system does not create a new inode or copy the data. Instead, it creates a new name entry in a directory and increments the reference count of the existing inode. The file\u0026rsquo;s data blocks are only deallocated when this reference count drops to zero. Removing a file link, an operation known as \u0026ldquo;unlinking\u0026rdquo;, decrements this count.\nThe following example demonstrates this concept. First, let\u0026rsquo;s inspect a new file:\n1 2 3 $ ls -il total 0 3558217 -rw-rw-r-- 1 burak burak 0 Sep 6 17:54 document.md The first column in the output is the inode number (3558217), and the third column is the reference count (1). Now, let\u0026rsquo;s create a hard link to the file:\n1 2 3 4 5 $ ln document.md document-linked.md $ ls -il total 0 3558217 -rw-rw-r-- 2 burak burak 0 Sep 6 17:54 document-linked.md 3558217 -rw-rw-r-- 2 burak burak 0 Sep 6 17:54 document.md After creating a hard link named document-linked.md, the output shows that both filenames point to the same inode number. The reference count for that inode has now increased to 2.\nFinally, if one of the links is removed, the reference count is decremented.\n1 2 3 $ rm document-linked.md \u0026amp;\u0026amp; ls -il total 0 3558217 -rw-rw-r-- 1 burak burak 0 Sep 6 17:54 document.md The inode and its data persist as long as the reference count is greater than zero.\nIt\u0026rsquo;s good practice to monitor inode usage on your system. Even if your disk has sufficient storage space, you might still get \u0026ldquo;no space left on device\u0026rdquo; or similar errors. This can happen if a process creates a massive number of small files.\nThe issue, in this case, isn\u0026rsquo;t a lack of storage capacity, but rather a shortage of available inodes to track new files. Since Linux uses an inode to manage every file and directory, a faulty process that creates too many files can exhaust all available inodes. For instance, if your HTTP server creates a lot of temporary files, sessions, etc, then you might face such issues at scale.\nTherefore, monitoring inode usage is crucial for system health.\nFile Descriptors A file descriptor is a small, non-negative integer that acts as a handle for an open file. When your process opens or creates a file, the kernel returns this number, which your program then uses to perform all further operations, like reading from or writing to that file.\nThere are special file descriptors for processes (except daemons) in Linux: 0 (stdin), 1 (stdout), and 2 (stderr), called stdin, stdout, and stderr. By convention, the shell automatically opens these three standard file descriptors for every new process it starts:\nBecause these first three numbers are reserved, the first file you open in a program will typically be assigned the next available file descriptor, which is 3.\nThe open() system call manual provides a clear definition of a file descriptor:\n“The return value of open() is a file descriptor, a small, integer that is an index to an entry in the process\u0026rsquo;s table of open file descriptors. The file descriptor is used in subsequent system calls to refer to the open file. The file descriptor returned by a successful call will be the lowest-numbered file descriptor not currently open for the process.” ^1\nAs this description states, a file descriptor is an integer that serves as an index in a per-process table. The kernel maintains a separate file descriptor table for each process, and the number returned by open() is simply the lowest available index in that table. If the kernel cannot open a file, it will typically return -1 to indicate an error. Because each process has its own table, a file descriptor in one process is independent of those in another.\nThis per-process table, however, is only the first part of the structure. Each entry in the file descriptor table points to a second data structure: the system-wide open file table. An entry in this table, often called an \u0026ldquo;open file description,\u0026rdquo; records information like the current file offset and status flags (e.g., read-only, append-only). A file descriptor\u0026rsquo;s reference to an open file description is unaffected even if the original file path is later removed or changed.\nFinally, each entry in the system-wide open file table points to the file\u0026rsquo;s inode, which contains the metadata and pointers to the actual data on disk.\nWith that being said, we can extend our simplified drawing above as follows:\nThe relationship between these tables is important when a process is forked. When fork() is called, the child process receives a copy of the parent\u0026rsquo;s file descriptor table. Crucially, the corresponding file descriptors in both the parent and child tables point to the same entry in the system-wide open file table. This means that they share a file offset; if the child reads from the file, the offset advances for the parent as well.\nIn contrast, processes that are completely independent of each other have separate file descriptor tables that do not share these underlying open file descriptions.\nMonitoring file descriptors is a helpful practice for SREs and system administrators. It\u0026rsquo;s likely to face \u0026ldquo;too many open files\u0026rdquo; errors in day-to-day operations, even in staging environments. These errors often occur when an application forgets to close files after using them, causing a resource leak over time.\nA steady increase in the number of open file descriptors is a strong indicator of a leak in an application\u0026rsquo;s logic.\nYou can start by checking /proc/sys/fs/file-nr to get an overall picture of file descriptor usage on the system.\nThe three values in file-nr denote the number of allocated file handles, the number of allocated but unused file handles, and the maximum number of file handles, reference:Kernel.org.\nTo identify the specific processes consuming the most file descriptors, you can run the following command. Note that it may take some time to complete.\n1 sudo lsof -n | awk \u0026#39;{print $2}\u0026#39; | sort | uniq -c | sort -rn | head -n 10 After identifying the process IDs (PIDs), you can use ps -fn \u0026lt;pid\u0026gt; to understand what each process is doing.\nAlso, you can inspect the open files for a specific process with lsof -p \u0026lt;pid\u0026gt;. This helps identify the source of a leak, such as unclosed temporary files or TCP connections that aren\u0026rsquo;t terminating properly.\nSockets Sockets provide a standard way for processes to communicate with one another, a mechanism known as Inter-Process Communication (IPC). This communication can occur between processes on the same host using Unix Domain Sockets (UDS), or between processes on different hosts across a network. Sockets are the fundamental application programming interface (API) for network protocols like TCP and UDP within the TCP/IP suite.\nThe three most common types of sockets are Stream, Datagram, and Unix Domain sockets. Working with them involves a set of key system calls, such as socket(), bind(), listen(), accept(), and connect().\nThe process begins with the socket() system call, which creates a communication endpoint and returns a socket descriptor. This descriptor is implemented as a file descriptor, allowing programs to use many standard file-related calls like read() and write() to send and receive data. However, not all file operations apply to sockets; for example, a syscall lseek() has no meaning for a socket stream and cannot be used.\nPassive Socket A server follows a specific sequence of system calls to establish a listening socket capable of accepting client connections.\nsocket(): This call creates an endpoint for communication and returns a file descriptor that references it. This is the initial step for both clients and servers.\nbind(): This associates the socket file descriptor with a specific network address, which consists of an IP address and a port number. The kernel now knows where to send incoming packets destined for this socket.\nlisten(): This call marks the socket as a passive one, indicating that it will be used to accept incoming connection requests. The listen() call also takes a backlog parameter, which defines the maximum length of the queue for pending connections.\naccept(): This call extracts the first connection request from the queue of the listening socket, creates a new connected socket dedicated to that specific client, and returns a new file descriptor for it. The original listening socket remains open and continues to listen for other clients.\nread() / write(): All subsequent communication with the client, such as sending and receiving data, occurs on the new file descriptor returned by accept().\nclose(): When communication is finished, the socket file descriptor is closed.\nActive Socket The client-side setup is more straightforward.\nsocket(): Just like the server, the client first creates a socket endpoint.\nconnect(): This call establishes a connection from the client\u0026rsquo;s socket to the server\u0026rsquo;s listening address. Once this call succeeds, the two-way communication channel is established.\nA common best practice for handling connection errors is to completely close the socket file descriptor with close() and then create a new one before attempting to connect() again. Reusing the same file descriptor in subsequent connect() calls after an error can lead to unpredictable behavior across different operating systems. For example, some BSD-derived implementations may fail, so creating a new socket is the most portable approach.\n","permalink":"https://buraksekili.github.io/articles/inodes-filedescriptors-sockets/","summary":"\u003cp\u003eI\u0026rsquo;ve always found the best way to learn something is to try and write it down. This post is the result of that process, a collection of my personal notes (zettelkasten) aimed at connecting the dots between three fundamental concepts in Linux: inodes, file descriptors, and sockets. So, this post is just a cleaned-up version of my personal notes, explaining how inodes (representing files on disk), file descriptors (used by programs), and sockets (for network communication) all fit together.\u003c/p\u003e","title":"Notes on i-nodes, File Descriptors, and Sockets"},{"content":"Kubernetes Client-Side Indexing This post is part of Kubernetes controller development. Check out the first part on Diving into controller-runtime | Manager if you are interested in controller-runtime.\nWhen working with Kubernetes Operators, read requests (get and list) to the Kubernetes API server are handled by an in-memory cache that is maintained by client-go to reduce the load on your API server. This cache can be enhanced with indexes to retrieve resources more efficiently.\nThis post explains the underlying indexing implementation in controller-runtime (and in client-go). We\u0026rsquo;ll explore how indexing works under the hood in these Kubernetes client libraries.\nIf you\u0026rsquo;re interested in practical examples of indexing, the Kubebuilder book and controller-runtime package documentation provide great practical examples and implementations.\nPurpose of Indexing Indexing in Kubernetes client libraries (client-go and controller-runtime) optimizes the performance of Kubernetes controllers by enabling efficient lookups of cached objects based on specific attributes or relationships. This is crucial for:\nEfficient Resource Retrieval: Finding resources matching certain criteria without scanning the entire cache. This is particularly useful when managing resources that depend on other resources.\nReduced API Server Load: Minimizing the number of API calls to the Kubernetes API server through caching. Most modern Kubernetes Operators utilize controller-runtime, where this behavior comes by default.\nResponsive Reconciliation: Enabling controllers to react to changes in related resources. This allows you to reconcile specific resources based on changes in their dependencies.\nLet\u0026rsquo;s explore these concepts through an example.\nScenario We\u0026rsquo;ll examine a simplified version of an example from the Kubebuilder book.\nNote: We\u0026rsquo;ll use controller-runtime in our examples. For general information about Kubernetes Operators and controller-runtime, please refer to my previous post.\nConsider a Custom Resource Definition (CRD) called MyApp that deploys your application on Kubernetes and uses a ConfigMap for application-specific configurations.\nThe MyApp spec references a ConfigMap which includes MyApp specific configuration. The MyApp controller reconciles the desired state based on the following MyApp custom resource:\n1 2 3 4 5 6 7 8 apiVersion: my.domain/v1alpha1 kind: MyApp metadata: name: myapp-staging spec: config: configMapRef: name: \u0026#34;myapp-staging-conf\u0026#34; When a ConfigMap specified via spec.config.configMapRef.name is updated, MyApp should reflect those changes. To achieve this, MyApp needs to watch ConfigMap resources.\nA basic initialization of the MyApp controller looks like this:\n1 2 3 ctrl.NewControllerManagedBy(mgr). For(\u0026amp;v1alpha1.MyApp{}). Owns(\u0026amp;corev1.ConfigMap{}) Here, the controller manages MyApp CR as the primary resource and ConfigMap as a secondary resource. The controller will reconcile on both MyApp CR and ConfigMap events (e.g., updates to either resource).\nWhile this approach works, its efficiency is arguable since the controller will reconcile on every change to MyApp and ConfigMap resources. For example, changes to ConfigMaps unrelated to MyApp configuration will trigger reconciliation. Since reconciliation logic is often costly, involving external API calls or write requests to the Kubernetes API, we should avoid unnecessary reconciliations.\nThere are various ways to filter reconciliation requests, but the idiomatic approach uses Predicates and Event handlers. Since I covered these in previous blog post, we\u0026rsquo;ll focus on scenarios where indexing is crucial.\nConsider three MyApp instances:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 apiVersion: my.domain/v1alpha1 kind: MyApp metadata: name: myapp-staging1 spec: config: configMapRef: name: \u0026#34;myapp-staging-conf\u0026#34; --- apiVersion: my.domain/v1alpha1 kind: MyApp metadata: name: myapp-staging2 spec: config: configMapRef: name: \u0026#34;myapp-staging-conf\u0026#34; --- apiVersion: my.domain/v1alpha1 kind: MyApp metadata: name: myapp-dev spec: config: configMapRef: name: \u0026#34;myapp-dev-conf\u0026#34; Here, myapp-staging1 and myapp-staging2 use a ConfigMap called myapp-staging-conf, while myapp-dev uses myapp-dev-conf.\nIn our reconciler, when a ConfigMap is updated, we want to update only the MyApp instances that use that particular ConfigMap. This is where indexing becomes handy, allowing us to somehow correlate MyApp instances with their corresponding ConfigMaps.\nIndexing Implementation To find dependent MyApp instances, we need to find all MyApp instances using a particular ConfigMap. For example, when myapp-staging-conf is updated, we want to trigger reconciliation for both myapp-staging1 and myapp-staging2.\nTo achieve that, we will add an index to the MyApp custom resource containing the name of its associated ConfigMap. This enables efficient retrieval of MyApp resources through this index.\nIn controller-runtime, indexers are configured through the Cache interface, which provides methods to index and retrieve Kubernetes objects efficiently. The cache wraps client-go informers and provides additional capabilities, including indexing.\nWhen creating a new manager with ctrl.NewManager(), it initializes a cache (cache.Cache) to hold informers and indexers.\nBefore starting the manager, add indexers via the FieldIndexer:\n1 2 3 4 5 6 7 8 9 10 mgr.GetFieldIndexer().IndexField( context.Background(), \u0026amp;v1alpha1.MyApp{}, \u0026#34;spec.config.configMapRef.name\u0026#34;, // Can be any string, not limited to field names func(obj client.Object) []string { myApp := obj.(*v1alpha1.MyApp) cmName := myApp.Spec.Config.ConfigMapRef.Name return []string{cmName} }, ) This indexes MyApp resources based on the myApp.Spec.Config.ConfigMapRef.Name field. When mgr.Start() is called, the cache initializes all informers and configures the indexers.\nIn the reconciler, we can use controller-runtime client with indexing capabilities to efficiently query objects:\n1 2 3 4 5 6 myAppList := \u0026amp;v1alpha1.MyAppList{} listOps := \u0026amp;client.ListOptions{ FieldSelector: fields.OneTermEqualSelector(\u0026#34;spec.config.configMapRef.name\u0026#34;, \u0026#34;myapp-staging-conf\u0026#34;), } r.List(ctx, myAppList, listOps) This lists all MyApp resources that use the ConfigMap \u0026ldquo;myapp-staging-conf\u0026rdquo;. The Kubernetes client searches the cache using the index key \u0026ldquo;spec.config.configMapRef.name\u0026rdquo;.\nFinishing the Controller initialization Now that we can list MyApp resources based on their associated ConfigMap, we can avoid unnecessary reconciliations. For example, when myapp-staging-conf is updated, we don\u0026rsquo;t need to reconcile the myapp-dev resource since it uses a different ConfigMap.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ctrl.NewControllerManagedBy(mgr). For(\u0026amp;v1alpha1.MyApp{}). Watches( \u0026amp;corev1.ConfigMap{}, handler.EnqueueRequestsFromMapFunc( func(ctx context.Context, configMap client.Object) []reconcile.Request { myAppList := \u0026amp;v1alpha1.MyAppList{} listOps := \u0026amp;client.ListOptions{ FieldSelector: fields.OneTermEqualSelector( \u0026#34;spec.config.configMapRef.name\u0026#34;, configMap.GetName(), ), } if err := r.List(ctx, myAppList, listOps); err != nil { return []reconcile.Request{} } requests := make([]reconcile.Request, len(myAppList.Items)) for i := range myAppList.Items { requests[i] = reconcile.Request{ NamespacedName: types.NamespacedName{ Name: myAppList.Items[i].Name, Namespace: myAppList.Items[i].Namespace, }, } } return requests }), builder.WithPredicates(predicate.NewPredicateFuncs( func(object client.Object) bool { // No ConfigMap filtering currently. // Add predicate functions here to filter ConfigMaps // For example, consider ConfigMaps with specific // annotations like `myapp/config` // The Enqueue function runs based on this return value return true }), ), ). Complete(r) Instead of owning all ConfigMap resources, the controller now watches ConfigMaps. With the help of predicate functions, we can filter ConfigMap resources events before enqueuing MyApp resources for reconciliation. After passing predicates, we specify which MyApp resources to reconcile within EnqueueRequestsFromMapFunc. Using our index, we can find MyApp instances using the updated ConfigMap, ensuring efficient reconciliation of only the relevant resources.\nHow While previous sections covered how to use controller-runtime for indexing resources, this section explores the underlying implementation details.\nKubernetes contains well-structured code patterns, and indexing is one of them. Although we used controller-runtime in our examples, it leverages client-go under the hood to handle the actual indexing operations.\nLet\u0026rsquo;s examine the implementation details that make indexing possible. While I can\u0026rsquo;t cover every implementation detail, we\u0026rsquo;ll focus on the most interesting aspects of controller-runtime and client-go\u0026rsquo;s indexing mechanisms.\nManager and Cache Setup The first step is instantiating a Manager from controller-runtime to handle the MyApp controller and its dependencies. We\u0026rsquo;ll use NewManager from controller-runtime/pkg/manager for manager instantiation.\nIf you\u0026rsquo;re new to Manager or want to understand its role in depth, check out my post on Diving into controller-runtime | Manager.\nAlthough Manager offers various configuration options, I\u0026rsquo;ll focus on the cache configuration, specifically the NewCache option. We typically use the default cache configuration for NewCache since it is a low-level primitive that rarely needs customization except in specific use cases. This is already mentioned in the docs, as follows:\n1 2 3 4 5 6 7 8 9 // NewCache is the function that will create the cache to be used // by the manager. If not set this will use the default new cache function. // // When using a custom NewCache, the Cache options will be passed to the // NewCache function. // // NOTE: LOW LEVEL PRIMITIVE! // Only use a custom NewCache if you know what you are doing. NewCache cache.NewCacheFunc By default, NewCache instantiates an informerCache instance from controller-runtime that uses NewSharedIndexInformer informer from client-go. The exception is when multi-namespace is configured for cache, in which case multiNamespaceCache from controller-runtime is used.\nIndex Field Implementation Now, our cache is instantiated and attached to Manager. What happens when we run following code piece to create an indexer for us?\n1 2 3 4 5 6 7 8 9 10 mgr.GetFieldIndexer().IndexField( context.Background(), \u0026amp;pkg.MyApp{}, \u0026#34;spec.config.configMapRef.name\u0026#34;, func(obj client.Object) []string { myApp := obj.(*pkg.MyApp) cmName := myApp.Spec.Config.ConfigMapRef.Name return []string{cmName} }, ) The function passed into IndexField will be referred as F later in the post.\nThe FieldIndexer here is the informerCache that we created while setting up the Manager, as mentioned above.\nIndexField gets informer of the given object, in our case MyAp, indexing key (spec.config.configMapRef.name), and a function F. In F, if you notice, we did not specify the namespace of the ConfigMap as it will be handled automatically by the controller-runtime under the hood.\ncontroller-runtime takes F and uses it in indexByField function (reference: here) and generates both namespaced and cluster-scoped variants of the extracted values.\nAll of these operations are wrapped in an anonymous function. This anonymous function actually runs F to get extracted values from each MyApp resources. The result of F will then be translated into special indexed value(s) as follows:\n__all_namespaces/\u0026lt;MyApp.metadata.name\u0026gt; \u0026lt;MyApp.metadata.namespace\u0026gt;/\u0026lt;MyApp.metadata.name\u0026gt; if resource (MyApp) is namespaced. In our case, since MyApp is namespaced resource (not cluster scoped resource such as ClusterRole), controller-runtime adds namespace for us. It also creates a special value with __all_namespaces/ prefix for our index key (spec.config.configMapRef.name) in order to allow listing regardless of the object namespace in cache.\nThen this anonymous function that wraps F is going to be passed into informer through adding an Indexer to the MyApp\u0026rsquo;s informer.\nUnderstanding Indexers and Indices We mentioned adding an Indexer to an informer but what is Indexer? What does it look like?\nIndexer is actual core component used in indexing logic. It keeps track of Indexer names and functions used to calculate indexed values, such as our F. Indexer names have a special format as field:\u0026lt;indexer_name\u0026gt;. So, our indexer name is going to be field:spec.config.configMapRef.name.\nIndexer and other related types are defined in client-go, as follows:\n1 2 3 4 5 6 7 8 9 10 11 // IndexFunc returns indexed values for objects, // such as ConfigMap names for MyApp resources like anonymous // function (that wraps F) mentioned above. type IndexFunc func(obj interface{}) ([]string, error) // Indexers maintain indexer names as keys and // their corresponding calculation functions as value. type Indexers map[string]IndexFunc // Indices stores the actual index data for each registered Indexer name. type Indices map[string]Index type Index map[string]sets.String For example, when we create a custom indexer named spec.config.configMapRef.name by calling IndexField, client-go adds it to the indexer with a special format:\nIndexers[field:spec.config.configMapRef.name]=\u0026lt;anonymous function generated in controller-runtime\u0026gt; Indices=nil Since we do not have any actual resource created at the time we call IndexField function, Indices is not yet populated; thus, nil.\nFor Indices and Index, assume that we already have a MyApp instance called myapptest.\nIndices will contain all indexes for the particular indexer. For our custom indexer field:spec.config.configMapRef.name, Indices is going to look like\n\u0026#34;field:spec.config.configMapRef.name\u0026#34; -\u0026gt; set(\u0026#34;default/myapptest\u0026#34;, \u0026#34;__all_namespaces/myapptest\u0026#34;) It contains all indexes calculated by the indexer called field:spec.config.configMapRef.name.\nCache Implementation Details Back to our actual work, recall that the anonymous function wrapping F needs to be passed to the informer by adding an Indexer to the MyApp\u0026rsquo;s informer. controller-runtime handles this here.\nThe MyApp\u0026rsquo;s Informer (of type sharedIndexInformer) takes this request and passes it to its indexer indexer field, which implements the Indexer interface.\nThe indexer field is implemented by cache that has a core field called cacheStorage serving as as the actual storage of the client-go cache. It implements ThreadSafeStore interface. Specifically, it uses threadSafeMap implementation.\nthreadSafeMap implementation uses items (map[string]interface{}) for objects in the cache, and index field which is a type of storeIndex.\n1 2 3 4 5 6 7 8 9 10 11 type threadSafeMap struct { lock sync.RWMutex items map[string]interface{} index *storeIndex } // storeIndex implements the indexing functionality for Store interface type storeIndex struct { indexers Indexers indices Indices } The Indexers and Indices we discussed earlier are implemented here in the client-go cache.\nIndexer in action With the indexer registered, let\u0026rsquo;s create an instance of MyApp CR and examine what happens.\nWhen creating a MyApp instance, processDelta function handles cache updates; either removes or updates keys from the cache.\nSince the cache in client-go uses threadSafeMap, it checks our object in its storage using the object\u0026rsquo;s key. The key is generated by MetaNamespaceKeyFunc, with \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; format.\nSince we are creating the resource for the first time, this key does not exist in the cache (specifially in threadSafeMap). That\u0026rsquo;s why, client-go adds the object (MyApp instance) to its cache.\nclient-go updates underlying cache storage (threadSafeMap) by inserting the object into the key.\nkey: default/myapp-staging1 value: *pkg.MyApp At the moment, we have two indexers: the default \u0026ldquo;namespace\u0026rdquo; indexer that works with \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; metadata of objects, and our custom indexer called \u0026ldquo;field:spec.config.configMapRef.name\u0026rdquo;. client-go iterates through these indexers and updates them one by one.\nThe cool part here is that client-go actually runs Update method under the hood, as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // First we call Add, where key: default/myapp-staging1 and value is the actual // MyApp resource instance. func (c *threadSafeMap) Add(key string, obj interface{}) { c.Update(key, obj) } // Then Update method is called by Add method. It checks for the given key on // the threadSafeMap (which is an actual storage used in client-go cache) items. // And runs updateIndices. func (c *threadSafeMap) Update(key string, obj interface{}) { c.lock.Lock() defer c.lock.Unlock() oldObject := c.items[key] c.items[key] = obj c.index.updateIndices(oldObject, obj, key) } // This doc is directly taken from client-go code. // // updateIndices modifies the objects location in the managed indexes: // - for create you must provide only the newObj // - for update you must provide both the oldObj and the newObj // - for delete you must provide only the oldObj // updateIndices must be called from a function that already has a lock on the cache func (i *storeIndex) updateIndices(oldObj interface{}, newObj interface{}, key string) { for name := range i.indexers { i.updateSingleIndex(name, oldObj, newObj, key) } } Based on the oldObj and newObj values, updateSingleIndex determines which keys need to be added to or removed from the index of the given indexer.\nThe index update process follows this pattern:\n1 2 3 4 5 6 7 8 9 10 11 12 objectKey := \u0026#34;default/myapp-staging1\u0026#34; indexerName := \u0026#34;field:spec.config.configMapRef.name\u0026#34; index := threadSafeMap.index.Indices[indexerName] // set corresponds to Set that contains all MyApp // resources that use myapp-staging-conf ConfigMap. set := index[\u0026#34;__all_namespaces/myapp-staging-conf\u0026#34;] if myAppListUsingSpecificConfigMap == nil { set = sets.String{} index[\u0026#34;__all_namespaces/myapp-staging-conf\u0026#34;] = set } set.Insert(objectKey) Using the Indexer When we call r.List(), controller-runtime checks if the object is uncached (or unstructured). In our case, the objects are cached, controller-runtime client tries to List all MyApp instances from the cache, as follows:\n1 return c.cache.List(ctx, obj, opts...) As we initialized informerCache (recall Manager setup), controller-runtime client calls informerCache\u0026rsquo;s List method (defined here). Now, in informerCache\u0026rsquo;s List method, we first get MyApp object\u0026rsquo;s informer. If the informer has started, we try to run List method on MyApp informer\u0026rsquo;s cache, which delegates operation to client-go.\nRecall the following code piece:\n1 2 3 4 5 6 7 8 myAppList := \u0026amp;pkg.MyAppList{} listOps := \u0026amp;client.ListOptions{ FieldSelector: fields.OneTermEqualSelector( \u0026#34;spec.config.configMapRef.name\u0026#34;, \u0026#34;myapp-staging-conf\u0026#34;, ), } r.List(ctx, myAppList, listOps) In the list options passed to r.List, we specified our indexer key. When using a FieldSelector, the cache requires an exact match for the selector. Then, controller-runtime goes through each Indexers (in ourcase we have two, one field:spec.config.configMapRef.name and namespace one.)\nSince we haven\u0026rsquo;t specified a Namespace in ListOpts, controller-runtime will look for the __all_namespaces/myapp-staging-conf indexed value in the index called field:spec.config.configMapRef.name.\n- indexName: \u0026#34;field:spec.config.configMapRef.name\u0026#34; indexName is derived from ListOptions - indexedValue: \u0026#34;spec.config.configMapRef.name\u0026#34; indexedValue is derived from ListOptions After getting this informations, controller-runtime actually forwards our request to client-go\u0026rsquo;s Indexer interface\u0026rsquo;s ByIndex method which is documented as follows:\n1 2 3 // ByIndex returns the stored objects whose set of indexed values // for the named index includes the given indexed value ByIndex(indexName, indexedValue string) ([]interface{}, error) Remember how we call this client-go method from controller-runtime\n1 objs, err = indexer.ByIndex(\u0026#34;field:spec.config.configMapRef.name\u0026#34;, \u0026#34;__all_namespaces/myapp-staging-conf\u0026#34;) Based on its documentation, ByIndex looks for stored objects for key \u0026ldquo;__all_namespaces/myapp-staging-conf\u0026rdquo; in the index of \u0026ldquo;field:spec.config.configMapRef.name\u0026rdquo; indexer\nThis may sound complicated but to simplify this flow, let\u0026rsquo;s re iterate through the following types:\n1 2 3 4 5 6 7 8 9 10 11 12 13 // the key is indexer\u0026#39;s name, such as \u0026#34;field:spec.config.configMapRef.name\u0026#34; // the value is IndexFunc, such as the anonymous function mentioned previously. type Indexer map[string]IndexFunc // the key is indexer\u0026#39;s name, such as \u0026#34;field:spec.config.configMapRef.name\u0026#34; // the value is Index type Indices map[string]Index // the key is indexed value, such as __all_namespaces/myapp-staging-conf // the value is set of strings that corresponds to // \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; metadata of the objects. // For ex, default/myapp-staging1 type Index map[string]sets.String Now, we have set including / metadata of the MyApp resources. Then, threadSafeMap converts this Set to a list, and List operation is done by using the indexing functionality that we added.\nConclusion Throughout this post, we\u0026rsquo;ve walked through Kubernetes client-side indexing, exploring both its practical use and internal workings. While this post shares one approach to using indexing for improving controller performance, there are many other patterns and best practices in the Kubernetes ecosystem that might better suit your specific needs.\nIf you\u0026rsquo;re interested in learning more about controller development, you might find my earlier post about Controller Runtime Manager helpful, where I shared my experience with the core components of controllers. The Kubebuilder documentation is also an excellent resource that provides more comprehensive examples and different indexing use cases.\nI hope sharing these experiences with client-side indexing has been helpful for your journey :) Every controller and operator has unique requirements, and I\u0026rsquo;d be interested to hear about your approaches to similar challenges. Feel free to share your thoughts or ask questions about implementing indexing in your controllers.\nIf you notice any mistakes or have feedback, feel free to reach out to me on Twitter, LinkedIn, or GitHub.\nReferences https://book.kubebuilder.io/ https://pkg.go.dev/sigs.k8s.io/controller-runtime ","permalink":"https://buraksekili.github.io/articles/client-k8s-indexing/","summary":"\u003ch2 id=\"kubernetes-client-side-indexing\"\u003eKubernetes Client-Side Indexing\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThis post is part of Kubernetes controller development.\nCheck out the first part on \u003ca href=\"../controller-runtime-1\"\u003eDiving into controller-runtime | Manager\u003c/a\u003e if you are interested in controller-runtime.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWhen working with Kubernetes Operators, read requests (get and list) to the Kubernetes API server are handled by an in-memory cache that is maintained by client-go to reduce the load on your API server. This cache can be enhanced with indexes to retrieve resources more efficiently.\u003c/p\u003e","title":"Kubernetes Client-Side Indexing"},{"content":"A thread pool is a software design pattern where a set of worker threads is created to execute tasks concurrently. Instead of creating a new thread for each task, which can be resource-intensive, tasks are submitted to the pool and executed by available worker threads.\nThis blog post will go through a simple thread pool implementation - similar to the one in Rust book - with a couple of simple enhancements.\nUnlike Go\u0026rsquo;s lightweight goroutines, Rust\u0026rsquo;s threads map directly to OS threads, making thread pools widely used technique for resource management and performance optimization.\nAt its core, a thread pool is a collection of worker threads that are ready to execute given tasks. Instead of spawning a new thread for each task - potentially costly operation in Rust - tasks are submitted to the pool and executed by available workers (threads). This pattern is useful in various scenarios: web servers handling multiple client connections, task scheduling systems processing queued jobs, parallel data processing applications crunching large datasets, I/O-bound applications managing concurrent operations, and more.\nThere are various benefits of thread pools. They offer resource management by limiting the number of active threads, preventing system resource exhaustion. Performance may be optimized as the overhead of repeated thread creation and destruction is eliminated. Thread pools also allow for predictable resource consumption, enabling developers to control and forecast the maximum thread usage. Load balancing comes as a natural consequence, with tasks distributed evenly across available threads.\nHowever, thread pools are not without their challenges.\nIntroducing additional complexity to the codebase, requiring careful management of shared state and synchronization to avoid pitfalls like deadlocks and race conditions, For very short-lived tasks, the overhead of task submission might outweigh the benefits. This means that sometimes if your task is not long-running or not compute expensive, sending this execution to another thread might be longer than the time spent on preparation of the task and sending it to a thread. Let\u0026rsquo;s say a task takes 1 ms to execute directly. If the overhead of submitting to and retrieving from the thread pool takes 10 ms, you\u0026rsquo;re spending 11 ms total instead of just 1. Determining the optimal pool size can be a tricky process as well. Contention or starvation may happen. For instance, while workers are busy with long running tasks, shorter tasks are waiting in line for a long time. In the context of Rust, additional language-specific considerations arise. The ownership system and Rust\u0026rsquo;s memory safety guarantees require careful implementation - that\u0026rsquo;s why I wanted to implement the pooling from scratch. It helped me to practice concurrency practices in Rust while considering ownership model.\nNow, let\u0026rsquo;s start implementing a thread pool in Rust.\nImplementation Please read Rust book\u0026rsquo;s thread pool section if you haven\u0026rsquo;t read before: https://rust-book.cs.brown.edu/ch20-02-multithreaded.html\nOur thread pool, as explained above, will have already initialized threads which are ready to execute a task. Here, we will use Worker to represents an individual thread in our pool.\nWorker Each worker runs in its own thread, continuously polling for jobs. Its purpose is to process the given jobs.\nYou may ask who gives the task to worker. Worker will poll the jobs from a queue which will be shared among all other workers. If no jobs are available, the worker needs to wait until another task is submitted to queue.\n1 2 3 4 5 6 7 8 struct Worker { // id corresponds to the arbitrary id for the thread // useful while debugging :) id: usize, // thread is the actual thread which is going // to execute a real task. thread: Option\u0026lt;thread::JoinHandle\u0026lt;()\u0026gt;\u0026gt;, } So, the requirements that we expect from the worker:\nIt will execute the task in its thread, Thread is part of Worker struct. So, we need to somehow implement a logic to get the task. We cannot store the task in Worker struct as the same thread (or Worker) can be reused after executing its task - this is the idea of the thread pooling. Thread safe queue to pull the tasks. It will be part of the constructor of the Worker. So that, when we spawn the thread, we also start listening this queue. The queue needs to be shared among all workers. That\u0026rsquo;s why it needs to be thread-safe. While creating a Worker, we will use std::thread and spawn the thread. In the closure of the thread, we will run our logic to pull tasks from the queue.\nIf there is a task on the queue, the thread will execute the task, and then waits for a next task to be scheduled for itself. As Worker needs to re-run tasks after executing a single one, it needs to run continous loop in order not to miss any task pushed into queue.\nIf no task is provided, the queue will return None. In that case, the thread needs to wait for next task to be scheduled. Therefore, thread needs to wait within the loop.\nThere are various way to do that but most simple one is sleeping. However, sleeping leads to busy-waiting which wastes CPU cycles. Also, if there are new tasks registered while the thread is sleeping, the worker will run the thread after a duration of sleep which causes a latency.\nInstead of sleeping, we will use Condvar which is a synchronisation primitive to allow threads to wait for some condition to become true. It\u0026rsquo;s often used in conjunction with a Mutex to provide a way for threads to efficiently wait for changes in shared state. So, we will use Condvar to wait for new tasks to be available as it allows immediate response when the job is available which improves thread utilization.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 impl Worker { fn new( id: usize, job_queue: Arc\u0026lt;SegQueue\u0026lt;Job\u0026gt;\u0026gt;, job_signal: Arc\u0026lt;(Mutex\u0026lt;bool\u0026gt;, Condvar)\u0026gt;, running: Arc\u0026lt;AtomicBool\u0026gt;, ) -\u0026gt; Worker { let thread = thread::spawn(move || loop { match job_queue.pop() { Some(Job::Task(task)) =\u0026gt; if let Err(_) = task() {}, Some(Job::Shutdown) =\u0026gt; { break; } None =\u0026gt; { let (lock, cvar) = \u0026amp;*job_signal; let mut job_available = lock.lock().unwrap(); while !*job_available \u0026amp;\u0026amp; running.load(Ordering::Relaxed) { job_available = cvar .wait_timeout(job_available, Duration::from_millis(100)) .unwrap() .0; } *job_available = false; } } }); Worker { id, thread: Some(thread), } } } Our queue depends on crossbeam\u0026rsquo;s crossbeam_queue::SegQueue which is a concurrent queue implementation. It\u0026rsquo;s designed for high-performance concurrent scenarios. Also, it is lock-free which is an important aspect of SegQueue.\nOur queue is actually a linked list of Job which will look like following:\n1 2 3 4 pub enum Job { Task(Box\u0026lt;dyn FnOnce() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; + Send + \u0026#39;static\u0026gt;), Shutdown, } Job has two possible values, Task and Shutdown.\nThe Shutdown job type allows us to break the loop and terminate the thread gracefully. If a thread receives a Shutdown from the queue, it will stop executing.\nOkay, now check the Task. I know it looks too complicated at first glance, it still looks complicated to me. I\u0026rsquo;ll try to break it down.\nBox\u0026lt;dyn FnOnce() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; + Send + 'static\u0026gt; Here we have two main parts; the FnOnce() and the return type of this closure, Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; + Send + 'static\nFnOnce(): It is a closure without taking any arguments. It is same as thread::spawn(|| {}) closure. helps us to prevent accidentally call a task multiple times when it\u0026rsquo;s not safe to do so. -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; is the return type of this closure. On success, it returns () (unit, or void). On error, it returns a boxed trait object of std::error::Error. Trait object is one of the ways in Rust to write polymorphic code. Especially, dynamic dispatch uses trait objects to resolve generic function calls at runtime.\nBox\u0026lt;dyn ...\u0026gt;: Box is used for heap allocation. dyn indicates a trait object, allowing for dynamic dispatch. Send: is a trait which ensures the closure can be safely sent between threads. 'static: is a lifetime bound ensuring the closure doesn\u0026rsquo;t contain any non-static references. 'static bound ensures a type is safe to use without lifetime constraints. Without 'static, we might create closures that reference stack-local variables, leading to use-after-free bugs. In the arguments of Worker::new method, the use of Arc allows safe sharing of the job queue and signaling mechanism between threads. This is crucial in Rust\u0026rsquo;s ownership model for concurrent programming. Otherwise, shared data cannot be used safely among multiple threads as it will cause lots of critical bugs.\nThread Pool 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 pub struct ThreadPool { // workers keep track of all worker threads. workers: Vec\u0026lt;Worker\u0026gt;, // job_queue corresponds to a shared queue for distributing jobs to workers. job_queue: Arc\u0026lt;SegQueue\u0026lt;Job\u0026gt;\u0026gt;, // job_signal is notifier for workers when new jobs are available. job_signal: Arc\u0026lt;(Mutex\u0026lt;bool\u0026gt;, Condvar)\u0026gt;, // running indicates whether the threadpool is actively running or not. // it is mainly checked by worker threads to understand the status // of the pool. running: Arc\u0026lt;AtomicBool\u0026gt;, } impl ThreadPool { pub fn new(size: usize) -\u0026gt; ThreadPool { assert!(size \u0026gt; 0); let job_queue = Arc::new(SegQueue::new()); let job_signal = Arc::new((Mutex::new(false), Condvar::new())); let mut workers = Vec::with_capacity(size); let running = Arc::new(AtomicBool::new(true)); for id in 0..size { workers.push(Worker::new( id, Arc::clone(\u0026amp;job_queue), Arc::clone(\u0026amp;job_signal), Arc::clone(\u0026amp;running), )); } ThreadPool { workers, job_queue, job_signal, running, } } pub fn execute\u0026lt;F\u0026gt;(\u0026amp;self, f: F) -\u0026gt; Result\u0026lt;(), ThreadPoolError\u0026gt; where F: FnOnce() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; + Send + \u0026#39;static, { // We create a new Job::Task, wrapping our closure \u0026#39;f\u0026#39; let job = Job::Task(Box::new(f)); // Push this job to our queue self.job_queue.push(job); // Signal that a new job is available let (lock, cvar) = \u0026amp;*self.job_signal; let mut job_available = lock.lock().unwrap(); *job_available = true; cvar.notify_all(); Ok(()) } } ThreadPool::new creates a fixed number of workers, each with shared access to the job queue and signaling mechanism.\nThreadPool::execute takes a generic parameter called F which implements FnOnce() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; + Send + 'static. This type is the same type used for Job::Task - so that we can use argument f as Job. The argument passed in execute is actually a task that needs to be run in any of the workers.\nFor example,\n1 2 3 4 5 let x = 3; pool.execute(move || { println!(\u0026#34;the task is running with value {}\u0026#34;, x); Ok(()) }) The execute will take closure function, f: F, as an argument and it is used as Job::Task wrapped in Box. Some of the reasons behind this are:\nallowing us to send different types of jobs through the same queue. Workers can distinguish between actual tasks and shutdown signals. providing a uniform type (or interface if you are familiar with interfaces in other languages) for our job queue. All items in the queue are of type Job, regardless of the closure they contain. But, why do we use Box? The Box is crucial here for several reasons:\nWe are using dyn FnOnce() which is a trait object. In Rust, trait objects must be behind a pointer, and Box provides this. Closures can capture variables from their environment - as we did in the example above - which makes their size unknown at compile time. Box puts the closure on the heap, giving it a known size (the size of a pointer) at compile time. Box allows us to take ownership of the closure and move it into the Job enum, which is necessary because the closure will be executed in a different thread. This design actually allows us to:\nHandle different types of jobs (tasks and shutdown signals) uniformly. Move closures between threads safely, respecting Rust\u0026rsquo;s ownership rules. Deal with closures of different sizes and types in a unified manner. Graceful Shutdown 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 impl ThreadPool { pub fn shutdown(\u0026amp;mut self, timeout: Duration) -\u0026gt; Result\u0026lt;(), ThreadPoolError\u0026gt; { let start = Instant::now(); // Step 1: Signal all workers to stop self.running.store(false, Ordering::SeqCst); // Step 2: Wake up all waiting threads let (lock, cvar) = \u0026amp;*self.job_signal; match lock.try_lock() { Ok(mut job_available) =\u0026gt; { *job_available = true; cvar.notify_all(); } Err(_) =\u0026gt; { // We couldn\u0026#39;t acquire the lock, but we\u0026#39;ve set running to false, // so workers will eventually notice println!(\u0026#34;Warning: Couldn\u0026#39;t acquire lock to notify workers. They will exit on their next timeout check.\u0026#34;); } } // Step 3: Wait for all workers to finish for worker in \u0026amp;mut self.workers { if let Some(thread) = worker.thread.take() { // Step 4: Calculate remaining time let remaining = timeout .checked_sub(start.elapsed()) .unwrap_or(Duration::ZERO); // Step 5: Check if we\u0026#39;ve exceeded the timeout if remaining.is_zero() { return Err(ThreadPoolError::ShutdownTimeout); } // Step 6: Wait for the worker to finish if thread.join().is_err() { return Err(ThreadPoolError::ThreadJoinError(format!( \u0026#34;Worker {} failed to join\u0026#34;, worker.id ))); } } } // Step 7: Final timeout check if start.elapsed() \u0026gt; timeout { Err(ThreadPoolError::ShutdownTimeout) } else { Ok(()) } } } To notify workers polling the queue, we set the running flag to false. This is an atomic operation that immediately signals all workers that a shutdown is in progress. Since all threads need to finish executing the task they assigned to or stop waiting for next job (through cvar.wait_timeout method in Worker::new method) for proper shutdown, job_available is set to true, which triggers all threads and we notify all threads waiting on the condition variable.\nWe use try_lock() instead of lock() while notifying the threads. This attempts to acquire the lock but returns immediately if it can\u0026rsquo;t, rather than waiting until acquiring the lock.\nIf the lock is acquired, we proceed as before: set job_available to true and notify all waiting threads. By doing that, we can ensure that idle workers that were waiting on cvar.wait_timeout will wake up and notice the shutdown signal.\nIf the lock is not acquire successfully, the shutdown process continues. As running is already set to false, which all workers check periodically and wait_timeout in Worker\u0026rsquo;s main loop will expire - so they\u0026rsquo;ll wake up eventually and notice that running is false.\nAfter sending signals to notify threads, then we iterate through all workers, attempting to join each thread. Before joining each thread, the remaining time is calculated based on our timeout. This ensures we respect the overall timeout even if a worker is stuck (e.g., in an infinite loop), the timeout ensures we don\u0026rsquo;t wait forever.\nTo use shutdown method explicitly, the Drop can be implemented where the shutdown method can be triggered whenver ThreadPool is dropped, such as ThreadPool variable going out of scope.\n1 2 3 4 5 6 7 impl Drop for ThreadPool { fn drop(\u0026amp;mut self) { if !self.workers.is_empty() { let _ = self.shutdown(Duration::from_secs(2)); } } } Implementing a thread pool in Rust offers a great opportunity to practice Rust\u0026rsquo;s concurrency and memory safety paradigms. Throughout this blog post, I\u0026rsquo;ve tried to explain some concepts such as atomic operations, condition variables, and Rust\u0026rsquo;s ownership system in a practical context. While the implementation provides a solid foundation, there\u0026rsquo;s always room for improvement and optimization - so, ofc not use it on anywhere :) There are plenty of great crates including crossbeam\u0026rsquo;s. I just developed this thread pooling to practice concepts aforementioned. Consider exploring advanced features like work stealing algorithms or dynamic pool sizing to further enhance performance.\nIf you notice any mistakes or have feedback, feel free to reach out to me on Twitter, LinkedIn, or GitHub.\nReferences https://doc.rust-lang.org/book/ch20-02-multithreaded.html https://github.com/crossbeam-rs/crossbeam ","permalink":"https://buraksekili.github.io/articles/thread-pooling-rs/","summary":"\u003cp\u003eA thread pool is a software design pattern where a set of worker threads is created to execute tasks concurrently.\nInstead of creating a new thread for each task, which can be resource-intensive, tasks are submitted to the pool and executed by available worker threads.\u003c/p\u003e\n\u003cp\u003eThis blog post will go through a simple thread pool implementation - similar to the one in Rust book - with\na couple of simple enhancements.\u003c/p\u003e","title":"Thread Pooling in Rust "},{"content":"Working with Custom Data Format in Rust using serde If you need to perform serialization or deserialization in Rust, you’ve most likely used the serde before. I’m currently learning Rust, and I found myself needing similar thing.\nTo get familiar with the Rust ecosystem, I decided to develop a simple key-value store. Initially, the engine for this key-value store was designed to work with JSON objects, as JSON is a widely-used format that’s straightforward to use with web clients. Also, as most of the languages and platforms already support JSON, it is a good choice to start with.\nWhat I wanted to achieve was that users send JSON objects to indicate their request, such as \u0026ldquo;give me the value of key \u0026rdquo;, which can be represented as { \u0026quot;key\u0026quot;: \u0026quot;some_key\u0026quot; } in JSON. The response is also formatted as a JSON object, like {\u0026quot;value\u0026quot;: \u0026quot;value_of_the_key\u0026quot;}. The concept and requirements of this server are quite simple and clear.\nI generally use Go for my projects, where the JSON serialization/deserialization process is straightforward. You can manage it with some tags on your struct, and the rest is handled by Go itself. In Rust, achieving the same thing is also straightforward with serde. You only need to add a few macros, and serde will automatically implement serialization and deserialization methods for you. As JSON is one of the most popular data formats, you can set this up with just a few lines of code. I am not going to give details about how to achieve this as serde documentation has handful examples regarding this.\nAfter checking similar projects, I realized that most of the engines do not use these widely adopted data formats in place with their storage engine. Of course, the reasons of this may vary but the fundamental concerns are more or less the same: performance and simplicity. In my case, users only get, set or rm the key. So, using JSON is a bit overkill here. I totally agree that it is quite straightforward to implement and get start with JSON but what happens if I want to introduce a simple - and to be honest useless and dumbest - data format to interact with my key-value storage engine? Considering that my learning purpose of Rust, the idea looks okay to me.\nThen, I started to focus on how to work with custom data format with serde? So that I can serialize Rust data types to my data format and deserialize some byte sequence such as strings back to Rust types?\nConcepts Before jumping into implementation details, it\u0026rsquo;d be better to get familiar with some core concepts that we are going to be using.\nData Format First things first, let’s try to understand what the data format is. Simply put, a data format defines how the data is stored and structured. For example, well-known data formats such as JSON, CSV, and TOML can store the same data but in different ways.\nYou probably use these formats on a daily basis as they are widely adopted and used. Almost every language support these data formats more or less. Although these formats use different syntax while representing the data, the underlying data they represent is the same.\nIn my case, I wanted to introduce a simple custom data format, which looks like this:\n+:\u0026lt;cmd_name\u0026gt; \u0026lt;key\u0026gt; \u0026lt;optional_value\u0026gt;: This format allows me to store a sequence of commands - essentially the requests that users send to the key-value engine, such as fetching a key - in a log file. This format is of course not complicated and maybe even not quite helpful compared to JSON but it is of course cleaner and easier for me to work with. For instance, using this format makes it easy for my parser to determine where a command request starts in the file, as each command is prefixed with +: and ends with a colon :.\nThis data format of course is NOT a JSON (or YAML, CSV and whatever) which means I cannot use existing deserializer of already knowns data formats. This means I need to implement my own basic serializer and deserializer to convert Rust data structures, such as enum or struct, into this custom format and vice versa.\nFor simple use cases like mine, you do not even need to write a full Serializer and Deserializer using serde. You can implement a custom deserialize method and a visitor to handle most tasks. My primary goal in creating these custom serializers and deserializers is to learn and understand the process better.\nData Type The data types refer to the way data is stored in memory and classified in the language that we use. In Rust and in many other languages, data types can be simple types such as integers, floating number, booleans and composite ones like structs, enums, and classes.\nOn the other hand, data format is how this data type is stored and structured in the storage.\nFor example, the following Get struct in Rust corresponds to the data type:\n1 2 3 struct Get { key: String, } where, storing this data type as a JSON string as {\u0026quot;key\u0026quot;: \u0026quot;some_key\u0026quot;} is the data format.\nSerialization and Deserialization With that being said, serialization is the process of converting or transforming these data types into a specific data format. For example, if you use a JSON serializer, it will convert your Rust data types into a JSON compatible string representation.\nThe deserialization is kind of the reverse process of the serialization where it takes your input (like as a string, byte sequence or in binary) and converts this input back into the data types, which might be struct or vector etc.\nSerialization As clearly mentioned in serde documentation, serde is NOT a parsing library. So, i am not going to dive into how to parse the stream.\nIn our case, the request that users send is represented as enum type, as follows:\n1 2 3 4 5 pub enum Request { Get { key: String }, Set { key: String, val: String }, Rm { key: String }, } First start with serializing this data type into our custom data format:\n+:\u0026lt;cmd_name\u0026gt; \u0026lt;key\u0026gt; \u0026lt;optional_value\u0026gt;: In order to serialize our enum, we need to implement Serialize trait for our Request type. This trait only has one required method called serialize. For most of the time, you do not need to implement the trait from scratch. There is a helper procedural macro called serde_derive to implement the trait for you. So, let\u0026rsquo;s add this macro to our type.\n1 2 3 4 5 6 7 8 use serde::Serialize; #[derive(Serialize)] pub enum Request { Get { key: String }, Set { key: String, val: String }, Rm { key: String }, } Eventually, this macro generates the following code (which shows the generated code in simplified manner) for Request struct.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // for more, please check https://docs.rs/serde/1.0.208/serde/ser/trait.Serialize.html impl Serialize for Request { fn serialize\u0026lt;S\u0026gt;(\u0026amp;self, serializer: S) -\u0026gt; Result\u0026lt;S::Ok, S::Error\u0026gt; where S: Serializer, { match *self { Request::Get { ref key } =\u0026gt; { let mut s = serializer.serialize_struct_variant(\u0026#34;Request\u0026#34;, 0, \u0026#34;Get\u0026#34;, 1)?; s.serialize_field(\u0026#34;key\u0026#34;, key)?; s.end() } Request::Set { ref key, ref val } =\u0026gt; { let mut s = serializer.serialize_struct_variant(\u0026#34;Request\u0026#34;, 1, \u0026#34;Set\u0026#34;, 2)?; s.serialize_field(\u0026#34;key\u0026#34;, key)?; s.serialize_field(\u0026#34;val\u0026#34;, val)?; s.end() } Request::Rm { ref key } =\u0026gt; { let mut s = s.serialize_struct_variant(\u0026#34;Request\u0026#34;, 2, \u0026#34;Rm\u0026#34;, 1)?; s.serialize_field(\u0026#34;key\u0026#34;, key)?; s.end(s) } } } } Instead of manually running serialize_field on each field of our enum, the macro will automatically generate the necessary code for us. This makes it easier to use in most cases.\nTo understand the flow, let’s break down what the serialize method does. It knows how to instruct Serializer to serialize the Request struct. Then, for each field in the enum, it calls serialize_field by using Serializer that is passed to serialize method.\nIf you want to use an existing serializer, like a JSON serializer, you can pass that serializer into the serialize method. The serializer will then handle the serialization process for you, converting your Rust data types into a JSON compatible format.\nHowever, in our case, we want to serialize the Request data type into our custom data format, which is not compatible with JSON or any other standard data formats. This means we need to implement our own custom serialization logic to handle this specific format - at least as scope of this blog post :).\nTo write our own Serializer, we need to implement serde::ser::Serializer trait. If you check the trait, it includes lots of required methods. But of course, not all of these methods need to be implemented in every case. Most of the methods are related to serializing specific types, like structs or i32.\nIn our case, we need to serialize a struct type. Based on the code generated by Serialize macro, we call serialize_struct_variant method. Therefore, we\u0026rsquo;ll definitely need to implement this method.\nAlso, we need to specify some required associated types of Serializer trait: Ok, Error and SerializeStructVariant in the Serializer trait.\ntype Ok corresponds to the output type that we generate after serialization. In our case, we can use () for Ok value since we are going to store the the serialization result in-memory and then write it to io::Write.\ntype Error corresponds to the error type that we may face during serialization. For the error type, we can define a custom Error type by following conventions here.\ntype SerializeStructVariant corresponds to the type returned from the serialize_struct_variant method. We can set SerializeStructVariant to Self, meaning our Serializer will be returned as the result of the serialize_struct_variant method. This allows us to use the serialization methods that we define within our custom Serializer.\nHere’s a simplified version of what our Serializer implementation will look like (omitting other methods that we don\u0026rsquo;t need to implement):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 impl\u0026lt;\u0026#39;a\u0026gt; ser::Serializer for \u0026amp;\u0026#39;a mut KvRequestSerializer { type Ok = (); type Error = Error; type SerializeStructVariant = Self; fn serialize_struct_variant( self, _name: \u0026amp;\u0026#39;static str, _variant_index: u32, variant: \u0026amp;\u0026#39;static str, _len: usize, ) -\u0026gt; std::result::Result\u0026lt;Self::SerializeStructVariant, Self::Error\u0026gt; { let req_type = match variant { \u0026#34;Set\u0026#34; =\u0026gt; Ok(\u0026#34;set\u0026#34;), \u0026#34;Get\u0026#34; =\u0026gt; Ok(\u0026#34;get\u0026#34;), \u0026#34;Rm\u0026#34; =\u0026gt; Ok(\u0026#34;rm\u0026#34;), _ =\u0026gt; Err(Error::InvalidData(String::from(\u0026#34;invalid request provided\u0026#34;))), }?; self.output += \u0026#34;+:\u0026#34;; self.output += req_type; Ok(self) } // and other required methods and types... } impl\u0026lt;\u0026#39;a\u0026gt; ser::SerializeStructVariant for \u0026amp;\u0026#39;a mut KvRequestSerializer { type Ok = (); type Error = Error; fn serialize_field\u0026lt;T\u0026gt;( \u0026amp;mut self, _key: \u0026amp;\u0026#39;static str, value: \u0026amp;T, ) -\u0026gt; std::result::Result\u0026lt;(), Self::Error\u0026gt; where T: ?Sized + Serialize, { value.serialize(\u0026amp;mut **self)?; Ok(()) } fn end(self) -\u0026gt; std::result::Result\u0026lt;Self::Ok, Self::Error\u0026gt; { self.output += \u0026#34;:\\n\u0026#34;; Ok(()) } } So, for example in order to serialize Request::Get {key: \u0026quot;abc\u0026quot;}, based on the serialize method (which is generated by Serialize macro)\n1 2 3 4 5 6 7 8 9 10 11 // serialize_struct_variant returns Result\u0026lt;Self::SerializeStructVariant, Self::Error\u0026gt; // which means succesfull results yield Self::SerializeStructVariant. // In our case, we defined `type SerializeStructVariant` as Self again. // So, the result of `serialize_struct_variant` method will be `KvRequestSerializer`. // // In the following code, `s` is type of KvRequestSerializer // which implements SerializeStructVariant trait. So that we can serialize the structs. let mut s = serializer.serialize_struct_variant(\u0026#34;Request\u0026#34;, 0, \u0026#34;Get\u0026#34;, 1)?; // now, s points to KvRequestSerializer and we already implement SerializeStructVariant trait. s.serialize_field(\u0026#34;key\u0026#34;, key)?; s.end() This flow will be resulted through following process:\nKvRequestSerializer\u0026rsquo;s serialize_struct_variant method. Here, we have information about how our Rust data type look like. KvRequestSerializer\u0026rsquo;s serialize_field method in SerializeStructVariant trait implementation. Here, we know each key of the Request::Get enum and its values KvRequestSerializer\u0026rsquo;s serialize_str. Then we pass the value of key field to serialize_str. So that we can form our desired data format Lastly we call end method from SerializeStructVariant During the process, we store the result of each operation in the output field of our Serializer. At the end, we can pass this output to our desired output location.\nNow, we implemented our serializer. Let\u0026rsquo;s write a simple test to verify the result. Before jumping into test cases, let\u0026rsquo;s define a function that eases usage of our serializer.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 pub fn serialize\u0026lt;T: ser::Serialize\u0026gt;(request: \u0026amp;T) -\u0026gt; String { let mut serializer = KvRequestSerializer { output: String::new(), }; request.serialize(\u0026amp;mut serializer).expect(\u0026#34;failed to serialize\u0026#34;); serializer.output } #[test] fn test_serialization_request_struct() { use crate::request::Request; let get_request = Request::Get { key: \u0026#34;get_key_testing\u0026#34;.to_owned(), }; let expected_get = \u0026#34;+:get get_key_testing:\\n\u0026#34;; assert_eq!(serialize(\u0026amp;get_request), expected_get); } Now that our serializer works as expected, let\u0026rsquo;s move on to deserializing our custom data format into the Request type by implementing our own deserializer.\nDeserialization Writing a custom deserializer can be more complicated than writing a serializer. I found myself confused quite often while working on the implementation at first. However, I\u0026rsquo;ll try to simplify the explanation as much as possible.\nIn serde, deserialization is a two-phase process that involves both a Deserializer and a Visitor. Let\u0026rsquo;s start with the Deserializer.\nDeserializer is responsible for interpreting the input, which is a data format in form of string, byte, binary etc., and matching this input data format to serde data model, such as integer, sequence and so on. Here, the serde data model refers to the data types defined within serde, which correspond closely to Rust\u0026rsquo;s type system. For example, bool in serde corresponds to the boolean type in Rust. The serde documentation provides a clear explanation of the data model, including an example using OsString, which is highly recommended if you\u0026rsquo;re not already familiar with serde\u0026rsquo;s data model. Please refer to the docs https://serde.rs/data-model.html.\nOnce the Deserializer matches input data to the appropriate serde data model, a Visitor is then used to analyze this generic data and convert it into the specific data type we want to achieve.\nAlthough this process may sound complicated, let\u0026rsquo;s break it down using a concrete example based on our case. Suppose we have a string like get abc:. Our deserialize method will call deserialize_str on our custom deserializer. This flow is similar to how the Serializer calls serialize_struct_variant, knowing that the data type is a struct. In our case, we know that our data format is a string that contains a single request. Thus, we will call deserialize_str. As opposed to serialize method, now we do not need to use macro to autogenerate deserialize method for Request type. As we already know that the input data format will be a string, we will implement deserialize method in a way that it will call deserialize_str method of our custom deserializer.\nWhen the deserializer\u0026rsquo;s deserialize_str method is called, it will, in turn, call the visit_str method on a visitor that we provide. This means we need to implement our own Visitor to handle string representation of our custom data format. Finally, within the visit_str method of our Visitor, we will parse the string and create the corresponding Request enum type based on the input.\nLet\u0026rsquo;s try to implement this deserialization process. As we did with the Serializer, we\u0026rsquo;ll start with the deserialize method for our data type - Request enum - which will instruct our custom deserializer.\n1 2 3 4 5 6 7 8 impl\u0026lt;\u0026#39;de\u0026gt; de::Deserialize\u0026lt;\u0026#39;de\u0026gt; for Request { fn deserialize\u0026lt;D\u0026gt;(deserializer: D) -\u0026gt; Result\u0026lt;Self, D::Error\u0026gt; where D: de::Deserializer\u0026lt;\u0026#39;de\u0026gt;, { deserializer.deserialize_str(RequestVisitor) } } If we look at the deserialize method, you\u0026rsquo;ll notice that we pass our deserializer to this method (similar to how we did it with the serialize method). Since we know our custom data format is a string, we\u0026rsquo;ll directly call deserialize_str. This is actually suitable for our simple data format. However, we also need to pass a RequestVisitor as an argument to deserialize_str. This requires us to create a visitor that implements the de::Visitor trait. The RequestVisitor will process the string input and try to generate the appropriate Request enum.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 pub struct RequestVisitor; impl\u0026lt;\u0026#39;de\u0026gt; de::Visitor\u0026lt;\u0026#39;de\u0026gt; for RequestVisitor { type Value = Request; fn expecting(\u0026amp;self, formatter: \u0026amp;mut std::fmt::Formatter) -\u0026gt; std::fmt::Result { formatter.write_str(\u0026#34;a command in the format \u0026#39;+:\u0026lt;cmd\u0026gt; \u0026lt;required_key\u0026gt; \u0026lt;optional_value\u0026gt;\u0026#39;\u0026#34;) } fn visit_str\u0026lt;E\u0026gt;(self, cmd_str: \u0026amp;str) -\u0026gt; std::result::Result\u0026lt;Self::Value, E\u0026gt; where E: de::Error, { let inputs = cmd_str.split_whitespace().collect::\u0026lt;Vec\u0026lt;\u0026amp;str\u0026gt;\u0026gt;(); let len = inputs.len(); if len != 2 \u0026amp;\u0026amp; len != 3 { return Err(de::Error::custom( \u0026#34;invalid command request provided, valid commands are \u0026#39;get\u0026#39;, \u0026#39;set\u0026#39; and \u0026#39;rm\u0026#39;\u0026#34;, )); } let cmd_name = inputs[0]; let get_key = |k: \u0026amp;str| -\u0026gt; String { if k.ends_with(\u0026#34;:\u0026#34;) { return k.get(0..k.len() - 1).unwrap_or(k).to_owned(); } else if k.ends_with(\u0026#34;:\\n\u0026#34;) { return k.get(0..k.len() - 2).unwrap_or(k).to_owned(); } return k.to_owned(); }; let mut cmd_name = inputs[0]; if cmd_name.starts_with(\u0026#34;+:\u0026#34;) { cmd_name = cmd_name.trim().get(2..cmd_name.len()).unwrap_or(cmd_name); } let key = inputs[1]; match cmd_name { \u0026#34;get\u0026#34; =\u0026gt; Ok(Request::Get { key: get_key(key) }), \u0026#34;rm\u0026#34; =\u0026gt; Ok(Request::Rm { key: get_key(key) }), \u0026#34;set\u0026#34; =\u0026gt; { let val = inputs[2]; Ok(Request::Set { key: key.to_owned(), val: get_key(val), }) } _ =\u0026gt; Err(de::Error::custom( \u0026#34;invalid command is provided, valid commands are \u0026#39;get\u0026#39;, \u0026#39;set\u0026#39; and \u0026#39;rm\u0026#39;\u0026#34;, )), } } } The Visitor trait has only one required method: expecting which will be used in error messages. While other methods like visit_str have default implementations, we need to override and implement the methods necessary for our use case. In this case, since we are working with string values, we\u0026rsquo;ll implement visit_str, which will handle parsing the given string.\nFor our example, visit_str will expect strings like get abc:, set key value:, or rm key:. The visit_str method will attempt to convert these strings into the corresponding Request enum variants.\nFinally we can implement our deserializer which will simply call the visitor\u0026rsquo;s visit_str method, as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 pub struct Deserializer\u0026lt;\u0026#39;de\u0026gt; { input: \u0026amp;\u0026#39;de str, } impl\u0026lt;\u0026#39;de, \u0026#39;a\u0026gt; de::Deserializer\u0026lt;\u0026#39;de\u0026gt; for \u0026amp;\u0026#39;a mut Deserializer\u0026lt;\u0026#39;de\u0026gt; { type Error = Error; fn deserialize_str\u0026lt;V\u0026gt;(self, visitor: V) -\u0026gt; std::result::Result\u0026lt;V::Value, Self::Error\u0026gt; where V: de::Visitor\u0026lt;\u0026#39;de\u0026gt;, { self.input = self .input .strip_suffix(\u0026#34;\\r\\n\u0026#34;) .or(self.input.strip_suffix(\u0026#34;\\n\u0026#34;)) .unwrap_or(self.input); visitor.visit_str::\u0026lt;Self::Error\u0026gt;(\u0026amp;self.input) } // Rest of the deserialize_* methods ... // // As Serializer, i do not list them all here as there is a deserialize_* // method for almost all type. // // For more detail about it, please refer to the: // https://docs.rs/serde/1.0.208/serde/trait.Deserializer.html# } This approach keeps the deserialization process straightforward and clean. Now, let\u0026rsquo;s write a simple test scenario to verify our implementation.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fn deserialize\u0026lt;\u0026#39;a, T: de::Deserialize\u0026lt;\u0026#39;a\u0026gt;\u0026gt;(input: \u0026amp;\u0026#39;a str) -\u0026gt; Result\u0026lt;T\u0026gt; { let mut deserializer = Deserializer::from_str(input); let t = T::deserialize(\u0026amp;mut deserializer)?; Ok(t) } #[test] fn test_deserialize_set() { let data = r\u0026#34;set burak 123:\u0026#34;; let expected = Request::Set { key: \u0026#34;burak\u0026#34;.to_string(), val: \u0026#34;123\u0026#34;.to_string(), }; let result: Request = deserialize(data).expect(\u0026#34;failed to deserialize\u0026#34;); } I hope this post helps you get started with your own serde implementations. Since I am also a beginner in Rust, I encourage you to always refer to the official serde documentation as the primary source of truth.\nAlso, the source code is available on GitHub: https://github.com/buraksekili/kvs_protocol/\nIf you notice any mistakes or have feedback, feel free to reach out to me on Twitter, LinkedIn, or GitHub.\nReferences https://serde.rs/ https://owengage.com/writing/2021-08-14-exploring-serdes-data-model-with-a-toy-deserializer/ ","permalink":"https://buraksekili.github.io/articles/rust-serde/","summary":"\u003ch2 id=\"working-with-custom-data-format-in-rust-using-serde\"\u003eWorking with Custom Data Format in Rust using serde\u003c/h2\u003e\n\u003cp\u003eIf you need to perform serialization or deserialization in Rust, you’ve most likely used the \u003cem\u003eserde\u003c/em\u003e before.\nI’m currently learning Rust, and I found myself needing similar thing.\u003c/p\u003e\n\u003cp\u003eTo get familiar with the Rust ecosystem, I decided to develop a simple key-value store.\nInitially, the engine for this key-value store was designed to work with JSON objects, as JSON is a widely-used format that’s straightforward to use with web clients.\nAlso, as most of the languages and platforms already support JSON, it is a good choice to start with.\u003c/p\u003e","title":"Working with Custom Data Format in Rust using serde"},{"content":" This guide is a summary of AWS EKS Best practices documentation to help me to skim through some concepts that i usually refer to. For details, please have a look to official EKS docs mentioned on Resources section.\nEKS (Amazon Elastic Kubernetes Service) It manages Kubernetes control-plane on behalf of you, ensures that each cluster has its own control plane. So, as an end-user, you only need to handle your workloads in worker nodes. All control plane related stuff will be handled by AWS.\nControl plane provisions at least two Kubernetes API Servers and three etcd instances across three AZs in the AWS.\nEKS will monitor your control-plane and if it fails or falls down, EKS handles this situations so that you will have control planes at high availability.\nNetworking The control plane is deployed in a VPC managed by AWS. So, this VPC is not visible to customers. And in order to deploy EKS cluster (workloads, nodes etc\u0026hellip;), you need to deploy them into a VPC again which is different than the one managed by AWS.\nSo, this means that you have two VPCs - one is managed by AWS for control plane and the other is managed by customer for data plane (workloads).\nIn that case, you need to configure your VPC configuration carefully. Your VPC needs to connect AWS\u0026rsquo;s VPC where control plane is created in order to talk with API Server. Otherwise - if you VPC cannot communicate with AWS\u0026rsquo;s VPC -, your nodes cannot register Kubernetes control plane which prevents scheduler from scheduling pods to worker nodes.\nYour API Server\u0026rsquo;s endpoint can be public - which is default - or private. As a default option, EKS bootstraps an endpooint for API server. Optionally, you can enable private access to the Kubernetes API server. This means that the communication between the nodes and API server happens within the VPC.\nFor more details, please advise to EKS docs: https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html\nEKS both supports IPv4 and IPv6 but by default, it uses IPv4 and recommends having at least two subnets created in different AZs while creating the cluster.\ncluster subnets: subnets specified during cluster creation.\nVPC Your VPC must have sufficient number of IP addresses so that resources on the cluster can be assigned to an IP address. Your VPC must support DNS hostname and resolution support to allow nodes to register to the cluster. Subnet Two subnets in different AZs - in at least two AZs. Subnets must have at least six IP addresses - ideally at least 16 IP addresses for EKS. Subnets can be public or private but the recommend way is private subnets. If you need an ingress from internet to your Pods, make sure that you have at least 1 public subnet to deploy loadbalancers. In this case, loadbalancers can be deployed into public or private subnets based on your use case but the nodes should be deployed in private subnets if possible. If you want to deploy LB into a subnet, subnet needs specific tags. If the LB needs to be private, add kubernetes.io/role/internal-elb: 1, otherwise kubernetes.io/role/elb: 1. Service of LoadBalancer type To load balance the network traffic at L4, deploy kubernetes Service with type of LoadBalancer. In AWS, EKS provisions ALB (AWS Application Load Balancer) for you.\nMake sure that your VPC and Subnet requirements are met. ALB chooses one subnet from each AZ. If you tag kubernetes.io/cluster/my-cluster=shared public subnet(s), it enables creating Service of LoadBalancer\nSecurity Groups SGs are used to control communication between the control plane and worker nodes. When you provision a cluster, EKS creates a default SG and associates this SG to all nodes. The default rules allow all traffic communication between nodes and all outbound traffic to any destination.\nNode communication The recommended way is having a both private and public subnets with minimum of two public subnets and two private subnets where private subnets are in two AZs.\nYou can provision load balancers in public subnets which forwards traffic to the workloads (Pods) created on private subnets.\nCluster endpoint As mentioned above, EKS provisions the cluster with public-only cluster endpoint. The recommended way is to have public-private mode where Kubernetes API calls within your cluster (from control plane to worker nodes or vice versa) uses private VPC.\nCNI When you provision EKS cluster, Amazon Virtual Private Cloud (VPC) CNI is enabled by default\nLoad Balancing Choose ALB if your workloads runs HTTP/HTTPS. If your workloads run TCP, use NLB.\nFor EKS, there are two targets for the target group of your load balancer; instance and ip.\nTarget group forwards requests to the registered targets such as EC2 instance as per docs\nInstance target This target will be the node IP of the worker node.\nSo, the incoming traffic will be routed to worker node through NodePort, and then the Service of ClusterIP selects a pod to forward the traffic.\nThis process has extra network hops and also sometimes ClusterIP service might select a Pod which runs on different node (different AZ) which will increase the latency.\nIP target Now, the traffic will be directly forwarded to the Pods. So, it significantly reduces the latency as the process does not include hops between NodePort and Service.\nResources https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html https://aws.github.io/aws-eks-best-practices/ ","permalink":"https://buraksekili.github.io/articles/eks/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThis guide is a summary of AWS EKS Best practices documentation to help me to skim through\nsome concepts that i usually refer to. For details, please have a look to official EKS docs\nmentioned on \u003ca href=\"#resources\"\u003eResources\u003c/a\u003e section.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch1 id=\"eks-amazon-elastic-kubernetes-service\"\u003eEKS (Amazon Elastic Kubernetes Service)\u003c/h1\u003e\n\u003cp\u003eIt manages Kubernetes control-plane on behalf of you, ensures that each cluster has its own control plane.\nSo, as an end-user, you only need to handle your workloads in worker nodes. All control plane related stuff will be handled by AWS.\u003c/p\u003e","title":"Fundamental EKS requirements"},{"content":"Concurrency Channels Unbuffered channel If channel is unbuffered\n1 ch := make(chan struct{}) sending a data to channel will block the goroutine as the channel is nil.\n1 2 3 4 5 6 7 package main func main() { ch := make(chan struct{}) ch \u0026lt;- struct{}{} } Output of this program is:\n1 2 3 4 5 6 7 $ go run main.go fatal error: all goroutines are asleep - deadlock! goroutine 1 [chan send]: main.main() /Users/buraksekili/projects/concur/main.go:35 +0x30 exit status 2 As reading from non-nil channel blocks goroutine and since there is no other goroutine reading from this channel exists, the program panics.\nSo, to simply put, we have 1 goroutine in this program and it is blocked while sending the channel, all goroutines in this simple application stucked as blocked. Hence, the program fails as all goroutines are asleep - deadlock!\nSo, if we have another goroutine that helps main goroutine by receiving a data from the channel, the program won\u0026rsquo;t be paniced.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan struct{}) go func() { \u0026lt;-ch }() ch \u0026lt;- struct{}{} fmt.Println(\u0026#34;Done\u0026#34;) } Output:\n1 2 $ go run main.go Done First listen channel in another goroutine, then write data to it. In the example above, even the goroutine that receives a data from the channel executes the statement \u0026lt;-ch after main goroutine sends data to channel ch \u0026lt;- struct{}{}, as long as the goroutines are running, the program won\u0026rsquo;t panic.\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { ch := make(chan struct{}) go func() { time.Sleep(3 * time.Second) \u0026lt;-ch }() fmt.Println(\u0026#34;hangs here for 3 secs\u0026#34;) ch \u0026lt;- struct{}{} fmt.Println(\u0026#34;done\u0026#34;) } Main goroutine hangs while sending data to channel for 3 seconds while other goroutine was sleeping. This won\u0026rsquo;t cause deadlock, as sleeping or doing other computations like fetching data from database, waiting a response from HTTP server do not cause goroutine to fall into blocking state from running state.\nBuffered Channel Again, if we have the same example as above, but with buffered channels:\n1 2 3 4 5 6 7 8 9 10 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan struct{}, 1) ch \u0026lt;- struct{}{} fmt.Println(\u0026#34;done\u0026#34;) } Output:\n1 2 $ go run main.go done the program will not panic due to deadlock, as we specify capacity (buffer) for the channel. Main goroutine will write data to the buffer and continues to the execution.\nRegardless of whether the channel is buffered or unbuffered, receiving from a closed channel will NOT block your goroutine.\n1 2 3 4 5 6 7 8 9 10 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan struct{}) close(ch) v, ok := \u0026lt;-ch fmt.Printf(\u0026#34;v: %v, ok: %v\\n\u0026#34;, v, ok) } Output:\n1 2 $ go run main.go v: {}, ok: false Of course, you cannot send any value to closed channel, which will cause panic.\nThe second parameter ok corresponds to boolean value showing that if the value is sent to the channel before closing the channel. Hence, there was no value in the channel before closing it, the ok is false.\n1 2 3 4 5 6 7 8 9 10 11 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int, 1) ch \u0026lt;- 3 close(ch) v, ok := \u0026lt;-ch fmt.Printf(\u0026#34;v: %v, ok: %v\\n\u0026#34;, v, ok) } Output:\n1 2 $ go run main.go v: 3, ok: true ","permalink":"https://buraksekili.github.io/articles/concurrency/","summary":"\u003ch2 id=\"concurrency\"\u003eConcurrency\u003c/h2\u003e\n\u003ch2 id=\"channels\"\u003eChannels\u003c/h2\u003e\n\u003ch3 id=\"unbuffered-channel\"\u003eUnbuffered channel\u003c/h3\u003e\n\u003cp\u003eIf channel is unbuffered\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nx\"\u003ech\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e:=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003emake\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kd\"\u003echan\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estruct\u003c/span\u003e\u003cspan class=\"p\"\u003e{})\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003esending a data to channel will block the goroutine as the channel is nil.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003epackage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nx\"\u003emain\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003efunc\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\t\u003c/span\u003e\u003cspan class=\"nx\"\u003ech\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e:=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003emake\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kd\"\u003echan\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estruct\u003c/span\u003e\u003cspan class=\"p\"\u003e{})\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\t\u003c/span\u003e\u003cspan class=\"nx\"\u003ech\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;-\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estruct\u003c/span\u003e\u003cspan class=\"p\"\u003e{}{}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eOutput of this program is:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ go run main.go\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003efatal error: all goroutines are asleep - deadlock!\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003egoroutine \u003cspan class=\"m\"\u003e1\u003c/span\u003e \u003cspan class=\"o\"\u003e[\u003c/span\u003echan send\u003cspan class=\"o\"\u003e]\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emain.main\u003cspan class=\"o\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        /Users/buraksekili/projects/concur/main.go:35 +0x30\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexit\u003c/span\u003e status \u003cspan class=\"m\"\u003e2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eAs reading from non-nil channel blocks goroutine and since there is no other\ngoroutine reading from this channel exists, the program panics.\u003c/p\u003e","title":"Concurrency Notes in Go"},{"content":"Introduction controller-runtime package has become a fundamental tool for most Kubernetes controllers, simplifying the creation of controllers to manage resources within a Kubernetes environment efficiently. Users tend to prefer it over client-go.\nThe increased adoption of projects like Kubebuilder or Operator SDK has facilitated the creation of Kubernetes Operator projects. Users need to implement minimal requirements to start with Kubernetes controllers, thanks to these projects.\nAs a developer working on Kubernetes projects, I inevitably touch code pieces utilizing controller-runtime Whenever I dive into code base, I always learn something new about the underlying mechanism of Kubernetes.\nThrough this blog series, I aim to share my learning regarding controller-runtime consolidating my notes spread across various notebooks.\nThis article will specifically dive into the role of controller-runtime Manager.\nWhat are Controllers and Operators? controller-runtime has emerged as the go-to package for building Kubernetes controllers. However, it is essential to understand what these controllers - or Kubernetes Operators - are.\nIn Kubernetes, controllers observe resources, such as Deployments, in a control loop to ensure the cluster resources conform to the desired state specified in the resource specification (e.g., YAML files) 1.\nOn the other hand, according to Redhat, a Kubernetes Operator is an application-specific controller 2. For instance, the Prometheus Operator manages the lifecycle of a Prometheus instance in the cluster, including managing configurations and updating Kubernetes resources, such as ConfigMaps.\nRoughly both are quite similar. They provide a control loop to ensure the current state meets the desired state.\nThe Architecture of Controllers Since controllers are in charge of meeting the desired state of the resources in Kubernetes, they somehow need to be informed about the changes on the resources and perform certain operations if needed. For this, controllers follow a special architecture to\nobserve the resources, inform any events (updating, deleting, adding) done on the resources, keep a local cache to decrease the load on API Server, keep a work queue to pick up events, run workers to perform reconciliation on resources picked up from work queue. This architecture is clearly pictured in client-go documentation:\nreference: client-go documentation Most end-users typically do not need to interact with the sections outlined in blue in the architecture. The controller-runtime effectively manages these elements. The subsequent section will explain these components in simple terms.\nTo simply put, controllers use\ncache to prevent sending each getter request to API server, workqueue which includes the key of the object that needs to be reconciled, workers to process items reconciliation. Informer Informers watch Kubernetes API server to detect changes in resources that we want to. It keeps a local cache - in-memory cache implementing Store interface - including the objects observed through Kubernetes API. Then controllers and operators use this cache for all getter requests - GET and LIST - to prevent load on Kubernetes API server. Moreover, Informers invoke controllers by sending objects to the controllers (registering Event Handlers).\nInformers leverage certain components like Reflector, Queue and Indexer, as shown in the above diagram.\nReflector According to godocs:\nReflector watches a specified resource and causes all changes to be reflected in the given store.\nThe store is actually a cache - with two options; simple one and FIFO. Reflector pushes objects to Delta Fifo queue.\nBy monitoring the server (Kubernetes API Server), the Reflector maintains a local cache of the resources. Upon any event occurring on the watched resource, implying a new operation on the Kubernetes resource, the Reflector updates the cache (Delta FIFO queue, as illustrated in the diagram). Subsequently, the Informer reads objects from this Delta FIFO queue, indexes them for future retrievals, and dispatches the object to the controller.\nIndexer Indexer saves objects into thread-safe Store by indexing the objects. This approach facilitates efficient querying of objects from the cache.\nCustom indexers, based on specific needs, can be created. For example, a custom indexer can be generated to retrieve all objects based on certain fields, such as Annotations.\nMore details about how Kubernetes indexing works, check Kubernetes Client-Side Indexing.\nManager According to godocs\nmanager is required to create controllers and provides shared dependencies such as clients, caches, schemes, etc. Controllers must be started by calling Manager.Start.\nThe Manager serves as a crucial component for controllers by managing their operations. To put it simply, the manager oversees one or more controllers that watch the resources (e.g., Pods) of interest.\nEach operator requires a Manager to operate, as the Manager controls the controllers, webhooks, metric servers, logs, leader elections, caches, and other components.\nFor all dependencies managed by the Manager, please refer to the Manager interface\nController Dependencies As godocs mentioned, Manager provides shared dependencies such as clients, caches, schemes etc. These dependencies are shared among the controllers managed by the Manager. If you have registered two controllers with the Manager, these controllers will share common resources.\nReconciliation, or the reconcile loop, involves the operators or controllers executing the business logic for the watched resources. For example, a Deployment controller might create a specific number of Pods as specified in the Deployment spec.\nThe Client package exposes functionalities to communicate with the Kubernetes API 3. Controllers, registered with a specific Manager, utilize the same client to interact with the Kubernetes API. The main operations of the client include reading and writing.\nReading operations mostly utilize the cache to access the Kubernetes API, rather than accessing it directly, to reduce the load on the Kubernetes API. In contrast, write operations directly communicate with the Kubernetes API. However, this behavior can be modified so that read requests are directed to the Kubernetes API. Nevertheless, this is generally not recommended unless there is a compelling reason to do so.\nThe cache is also shared across controllers, ensuring optimal performance. Consider a scenario where there are n controllers observing multiple resources in a cluster. If a separate cache is maintained for each controller, n caches will attempt to synchronize with the API Server, increasing the load on API Server. Instead, controller-runtime utilizes a shared cache called NewSharedIndexInformer for all controllers registered within a manager.\nIn the diagram above, two controllers maintain separate caches where both send ListAndWatch requests to API Server. However, controller-runtime utilizes a shared cache, reducing the need for multiple ListAndWatch operations.\nreference: controller-runtime/pkg/cache/internal/informers.go Code Whether you use Kubebuilder, Operator SDK, or controller-runtime directly, operators necessitate a Manager to function. The NewManager from controller-runtime facilitates the creation of a new manager.\n1 2 3 4 5 6 var ( // Refer to godocs for details // .... // NewManager returns a new Manager for creating Controllers. NewManager = manager.New\t) Under the hood, NewManager calls New from the manager package.\n1 func New(config *rest.Config, options Options) (Manager, error) For a simple setup, we can create a new manager as follows\n1 2 3 4 5 6 7 8 9 10 11 12 13 import ( \u0026#34;log\u0026#34; ctrl \u0026#34;sigs.k8s.io/controller-runtime\u0026#34; \u0026#34;sigs.k8s.io/controller-runtime/pkg/manager\u0026#34; ) func main() { mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), manager.Options{}) if err != nil { log.Fatal(err) } } Though this code piece is sufficient to create a Manager, the crucial part involves configuring the Manager using manager.Options{}.\nManager Options manager.Options{} configures various dependencies, such as webhooks, clients, or leader elections under the hood.\nScheme As mentioned in the godocs:\nScheme is the scheme used to resolve runtime.Objects to GroupVersionKinds / Resources.\nSo, scheme helps us to register your objects Go type into GVK. If you are building operators, you will realize following code block in your operator:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; runtimeschema \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; utilruntime \u0026#34;k8s.io/apimachinery/pkg/util/runtime\u0026#34; \u0026#34;sigs.k8s.io/controller-runtime/pkg/scheme\u0026#34; ) var ( myscheme = runtime.NewScheme() // SchemeBuilder is used to add go types to the GroupVersionKind scheme SchemeBuilder = \u0026amp;scheme.Builder{ GroupVersion: runtimeschema.GroupVersion{ Group: \u0026#34;your.group\u0026#34;, Version: \u0026#34;v1alpha1\u0026#34;, }, } ) func init() { // Adds your GVK to the scheme that you provided, which is myscheme in our case. utilruntime.Must(SchemeBuilder.AddToScheme(myscheme)) } The scheme is responsible for registering the Go type declaration of your Kubernetes object into a GVK. This is significant as RESTMapper then translates GVK to GVR, establishing a distinct HTTP path for your Kubernetes resource. Consequently, this empowers the Kubernetes client to know the relevant endpoint for your resource.\nCache I mentioned cache a lot, but it is one of the most crucial piece of operators and controllers, where you can see its effect directly. As mentioned Controller Dependencies section, controller-runtime initializes NewSharedIndexInformer for our controllers under the hood. In order to configure cache, cache.Options{} needs to be utilized. There are again a couple of possible configurations possible but be careful while configuring your cache since it has an impact on performance and resource consumption of your operator.\nI specifically want to emphasize SyncPeriod and DefaultNamespaces\nSyncPeriod triggers reconciliation again for every object in the cache once the duration passes. By default, this is configured as 10 hours or so with some jitter across all controllers. Since running a reconciliation over all objects is quite expensive, be careful while adjusting this configuration.\nDefaultNamespaces configures caching objects in specified namespaces. For instance, to watch objects in prod namespace:\n1 2 3 4 5 manager.Options{ Cache: cache.Options{ DefaultNamespaces: map[string]cache.Config{\u0026#34;prod\u0026#34;: cache.Config{}}, }, } Controller The Controller field, in manager.Options{}, configures essential options for controllers registered to this Manager. These options are set using controller.Options{}.\nNotably, the MaxConcurrentReconciles attribute within this configuration governs the number of concurrent reconciles allowed. As detailed in the Architecture of Controllers section, controllers run workers to execute reconciliation tasks. These workers operate as goroutines. By default, a controller uses only one goroutine, but this can be adjusted using the MaxConcurrentReconciles attribute.\nAfter configuring the Manager\u0026rsquo;s options, the NewManager function generates the controllerManager structure, which implements the Runnable interface.\nDuring the creation of the controllerManager structure, controller-runtime initializes the Cluster to handle all necessary operations to interact with your cluster, including managing clients and caches.\nAll the settings provided within manager.Options{} are transferred to cluster.New() to create the cluster. This process calls the private function newCache(restConfig *rest.Config, opts Options) newCacheFunc, initiating the NewInformer, which uses the type SharedIndexInformer as referenced in the Controller Dependencies section.\nThe next step involves registering controllers to the Manager.\n1 2 3 ctrl.NewControllerManagedBy(mgr). // \u0026#39;mgr\u0026#39; refers to the controller-runtime Manager we\u0026#39;ve set up For(\u0026amp;your.Object{}). // The \u0026#39;For()\u0026#39; function takes the object your controller will reconcile Complete(r) // \u0026#39;Complete\u0026#39; builds the controller and starts watching. I will dive into the detailed explanation of the controller registration process in my future writings to avoid making this post excessively long.\nStarting Manager 1 2 3 4 5 // mgr corresponds to manager.Manager{} if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil { setupLog.Error(err, \u0026#34;problem running manager\u0026#34;) os.Exit(1) } Once the manager starts, all required runnables in the manager will start, in the order of\ninternal HTTP servers; health probes, metrics and profiling if enabled. webhooks, cache, controllers, leader election. For reference, check Start(context.Context) method of controllerManager struct.\nFeel free to suggest improvements on GitHub or through my Twitter\nReferences https://kubernetes.io/docs/concepts/architecture/controller/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/client\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://buraksekili.github.io/articles/controller-runtime-1/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/kubernetes-sigs/controller-runtime\"\u003e\u003ccode\u003econtroller-runtime\u003c/code\u003e\u003c/a\u003e package has become a fundamental tool for\nmost Kubernetes controllers, simplifying the creation\nof controllers to manage resources within a Kubernetes environment efficiently. Users tend to prefer it over\n\u003ca href=\"https://github.com/kubernetes/client-go\"\u003e\u003ccode\u003eclient-go\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe increased adoption of projects like \u003ca href=\"https://book.kubebuilder.io/\"\u003eKubebuilder\u003c/a\u003e or \u003ca href=\"https://sdk.operatorframework.io/\"\u003eOperator SDK\u003c/a\u003e\nhas facilitated the creation of Kubernetes Operator projects.\nUsers need to implement minimal requirements to start with Kubernetes controllers, thanks to these projects.\u003c/p\u003e\n\u003cp\u003eAs a developer working on Kubernetes projects, I inevitably touch code pieces utilizing \u003ca href=\"https://github.com/kubernetes-sigs/controller-runtime\"\u003e\u003ccode\u003econtroller-runtime\u003c/code\u003e\u003c/a\u003e\nWhenever I dive into code base, I always learn something new about the underlying mechanism of Kubernetes.\u003c/p\u003e","title":"Diving into controller-runtime | Manager"}]